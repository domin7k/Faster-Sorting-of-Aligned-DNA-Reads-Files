
@inproceedings{bojesen_performance_1999,
	address = {Berlin, Heidelberg},
	title = {Performance {Engineering} {Case} {Study}: {Heap} {Construction}},
	isbn = {978-3-540-48318-2},
	shorttitle = {Performance {Engineering} {Case} {Study}},
	doi = {10.1007/3-540-48318-7\_24},
	abstract = {The behaviour of three methods for constructing a binary heap is studied. The methods considered are the original one proposed by Williams [1964], in which elements are repeatedly inserted into a single heap; the improvement by Floyd [1964], in which small heaps are repeatedly merged to bigger heaps; and a recent method proposed, e. g., by Fadel et al. [1999] in which a heap is built layerwise. Both the worstcase number of instructions and that of cache misses are analysed. It is well-known that Floyd's method has the best instruction count. Let N denote the size of the heap to be constructed, B the number of elements that fit into a cache line, and let c and d be some positive constants. Our analysis shows that, under reasonable assumptions, repeated insertion and layerwise construction both incur at most cN/B cache misses, whereas repeated merging, as programmed by Floyd, can incur more than (dN log2B)/B cache misses. However, for a memory-tuned version of repeated merging the number of cache misses incurred is close to the optimal bound N/B.},
	language = {en},
	booktitle = {Algorithm {Engineering}},
	publisher = {Springer},
	author = {Bojesen, Jesper and Katajainen, Jyrki and Spork, Maz},
	editor = {Vitter, Jeffrey S. and Zaroliagis, Christos D.},
	year = {1999},
	keywords = {Cache Block, Cache Line, Outer Loop, Primitive Operation, Recursive Program},
	pages = {301--315},
}

@misc{noauthor_iostat1_nodate,
	title = {iostat(1) - {Linux} manual page},
	url = {https://man7.org/linux/man-pages/man1/iostat.1.html},
	urldate = {2024-05-30},
}

@misc{noauthor_approximate_2024,
	title = {Approximate sizes of sequencing run output folders {\textbar} {Illumina} {Knowledge}},
	url = {https://knowledge.illumina.com/instrumentation/general/instrumentation-general-reference_material-list/000001508},
	language = {en},
	urldate = {2024-05-26},
	month = may,
	year = {2024},
}

@misc{noauthor_storage_2011,
	title = {Storage and {Computation} {Requirements} {\textbar} {Strand} {NGS}},
	url = {https://www.strand-ngs.com/support/ngs-data-storage-requirements},
	abstract = {Strand NGS is Next generation sequencing data analysis tool. Supports DNA-Seq, RNA-Seq, ChIP-Seq, Methyl-Seq, MeDIP-Seq, small RNA-Seq, pathway analysis, downstream analysis},
	language = {en},
	urldate = {2024-05-26},
	month = may,
	year = {2011},
}

@misc{noauthor_samtools-markdup1_nodate,
	title = {samtools-markdup(1) manual page},
	url = {http://www.htslib.org/doc/samtools-markdup.html},
	urldate = {2024-05-26},
}

@article{chen_gencore_2019,
	title = {Gencore: an efficient tool to generate consensus reads for error suppressing and duplicate removing of {NGS} data},
	volume = {20},
	issn = {1471-2105},
	shorttitle = {Gencore},
	url = {https://doi.org/10.1186/s12859-019-3280-9},
	doi = {10.1186/s12859-019-3280-9},
	abstract = {Removing duplicates might be considered as a well-resolved problem in next-generation sequencing (NGS) data processing domain. However, as NGS technology gains more recognition in clinical application, researchers start to pay more attention to its sequencing errors, and prefer to remove these errors while performing deduplication operations. Recently, a new technology called unique molecular identifier (UMI) has been developed to better identify sequencing reads derived from different DNA fragments. Most existing duplicate removing tools cannot handle the UMI-integrated data. Some modern tools can work with UMIs, but are usually slow and use too much memory. Furthermore, existing tools rarely report rich statistical results, which are very important for quality control and downstream analysis. These unmet requirements drove us to develop an ultra-fast, simple, little-weighted but powerful tool for duplicate removing and sequence error suppressing, with features of handling UMIs and reporting informative results.},
	language = {en},
	number = {23},
	urldate = {2024-05-26},
	journal = {BMC Bioinformatics},
	author = {Chen, Shifu and Zhou, Yanqing and Chen, Yaru and Huang, Tanxiao and Liao, Wenting and Xu, Yun and Li, Zhicheng and Gu, Jia},
	month = dec,
	year = {2019},
	keywords = {Consensus reads, Deduplication, Next-generation sequencing, Unique molecular identifier},
	pages = {606},
}

@article{li_tabix_2011,
	title = {Tabix: fast retrieval of sequence features from generic {TAB}-delimited files},
	volume = {27},
	issn = {1367-4803},
	shorttitle = {Tabix},
	url = {https://doi.org/10.1093/bioinformatics/btq671},
	doi = {10.1093/bioinformatics/btq671},
	abstract = {Summary: Tabix is the first generic tool that indexes position sorted files in TAB-delimited formats such as GFF, BED, PSL, SAM and SQL export, and quickly retrieves features overlapping specified regions. Tabix features include few seek function calls per query, data compression with gzip compatibility and direct FTP/HTTP access. Tabix is implemented as a free command-line tool as well as a library in C, Java, Perl and Python. It is particularly useful for manually examining local genomic features on the command line and enables genome viewers to support huge data files and remote custom tracks over networks.Availability and Implementation:  http://samtools.sourceforge.net.Contact:  hengli@broadinstitute.org},
	number = {5},
	urldate = {2024-05-26},
	journal = {Bioinformatics},
	author = {Li, Heng},
	month = mar,
	year = {2011},
	pages = {718--719},
}

@article{neph_bedops_2012,
	title = {{BEDOPS}: high-performance genomic feature operations},
	volume = {28},
	issn = {1367-4803},
	shorttitle = {{BEDOPS}},
	url = {https://doi.org/10.1093/bioinformatics/bts277},
	doi = {10.1093/bioinformatics/bts277},
	abstract = {Summary: The large and growing number of genome-wide datasets highlights the need for high-performance feature analysis and data comparison methods, in addition to efficient data storage and retrieval techniques. We introduce BEDOPS, a software suite for common genomic analysis tasks which offers improved flexibility, scalability and execution time characteristics over previously published packages. The suite includes a utility to compress large inputs into a lossless format that can provide greater space savings and faster data extractions than alternatives.Availability:  http://code.google.com/p/bedops/ includes binaries, source and documentation.Contact:  sjn@u.washington.edu and jstam@u.washington.eduSupplementary information:  Supplementary data are available at Bioinformatics online.},
	number = {14},
	urldate = {2024-05-26},
	journal = {Bioinformatics},
	author = {Neph, Shane and Kuehn, M. Scott and Reynolds, Alex P. and Haugen, Eric and Thurman, Robert E. and Johnson, Audra K. and Rynes, Eric and Maurano, Matthew T. and Vierstra, Jeff and Thomas, Sean and Sandstrom, Richard and Humbert, Richard and Stamatoyannopoulos, John A.},
	month = jul,
	year = {2012},
	pages = {1919--1920},
}

@article{yang_transmission_2017,
	title = {Transmission of multidrug-resistant {Mycobacterium} tuberculosis in {Shanghai}, {China}: a retrospective observational study using whole-genome sequencing and epidemiological investigation},
	volume = {17},
	issn = {1473-3099, 1474-4457},
	shorttitle = {Transmission of multidrug-resistant {Mycobacterium} tuberculosis in {Shanghai}, {China}},
	url = {https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(16)30418-2/fulltext},
	doi = {10.1016/S1473-3099(16)30418-2},
	language = {English},
	number = {3},
	urldate = {2024-05-26},
	journal = {The Lancet Infectious Diseases},
	author = {Yang, Chongguang and Luo, Tao and Shen, Xin and Wu, Jie and Gan, Mingyu and Xu, Peng and Wu, Zheyuan and Lin, Senlin and Tian, Jiyun and Liu, Qingyun and Yuan, ZhengAn and Mei, Jian and DeRiemer, Kathryn and Gao, Qian},
	month = mar,
	year = {2017},
	pmid = {27919643},
	note = {Publisher: Elsevier},
	pages = {275--284},
}

@article{chen_personal_2012,
	title = {Personal {Omics} {Profiling} {Reveals} {Dynamic} {Molecular} and {Medical} {Phenotypes}},
	volume = {148},
	issn = {0092-8674, 1097-4172},
	url = {https://www.cell.com/cell/abstract/S0092-8674(12)00166-3},
	doi = {10.1016/j.cell.2012.02.009},
	language = {English},
	number = {6},
	urldate = {2024-05-26},
	journal = {Cell},
	author = {Chen, Rui and Mias, George I. and Li-Pook-Than, Jennifer and Jiang, Lihua and Lam, Hugo Y. K. and Chen, Rong and Miriami, Elana and Karczewski, Konrad J. and Hariharan, Manoj and Dewey, Frederick E. and Cheng, Yong and Clark, Michael J. and Im, Hogune and Habegger, Lukas and Balasubramanian, Suganthi and O'Huallachain, Maeve and Dudley, Joel T. and Hillenmeyer, Sara and Haraksingh, Rajini and Sharon, Donald and Euskirchen, Ghia and Lacroute, Phil and Bettinger, Keith and Boyle, Alan P. and Kasowski, Maya and Grubert, Fabian and Seki, Scott and Garcia, Marco and Whirl-Carrillo, Michelle and Gallardo, Mercedes and Blasco, Maria A. and Greenberg, Peter L. and Snyder, Phyllis and Klein, Teri E. and Altman, Russ B. and Butte, Atul J. and Ashley, Euan A. and Gerstein, Mark and Nadeau, Kari C. and Tang, Hua and Snyder, Michael},
	month = mar,
	year = {2012},
	pmid = {22424236},
	note = {Publisher: Elsevier},
	pages = {1293--1307},
}

@article{logsdon_long-read_2020,
	title = {Long-read human genome sequencing and its applications},
	volume = {21},
	copyright = {2020 Springer Nature Limited},
	issn = {1471-0064},
	url = {https://www.nature.com/articles/s41576-020-0236-x},
	doi = {10.1038/s41576-020-0236-x},
	abstract = {Over the past decade, long-read, single-molecule DNA sequencing technologies have emerged as powerful players in genomics. With the ability to generate reads tens to thousands of kilobases in length with an accuracy approaching that of short-read sequencing technologies, these platforms have proven their ability to resolve some of the most challenging regions of the human genome, detect previously inaccessible structural variants and generate some of the first telomere-to-telomere assemblies of whole chromosomes. Long-read sequencing technologies will soon permit the routine assembly of diploid genomes, which will revolutionize genomics by revealing the full spectrum of human genetic variation, resolving some of the missing heritability and leading to the discovery of novel mechanisms of disease.},
	language = {en},
	number = {10},
	urldate = {2024-05-26},
	journal = {Nature Reviews Genetics},
	author = {Logsdon, Glennis A. and Vollger, Mitchell R. and Eichler, Evan E.},
	month = oct,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	keywords = {Genetic variation, Genomics, Sequencing},
	pages = {597--614},
}

@incollection{kumar_snp_2016,
	title = {{SNP} {Discovery} {Through} {Next}-{Generation} {Sequencing} and {Its} {Applications}},
	isbn = {978-1-315-36508-4},
	abstract = {Molecular markers are widely used in plant genetic research and breeding. Single Nucleotide Polymorphisms (SNPs) are currently the marker 
of choice due to their large numbers in virtually all populations of individuals. The applications of SNP markers have clearly been demonstrated 
in human genomics where complete sequencing of the human genome 
led to the discovery of several million SNPs [1] and technologies to analyze large sets of SNPs (up to 1 million) have been developed. SNPs have 
been applied in areas as diverse as human forensics [2] and diagnostics 
[3], aquaculture [4], marker assisted-breeding of dairy cattle [5], crop 
improvement [6], conservation [7], and resource management in fisheries [8]. Functional genomic studies have capitalized upon SNPs located 
within regulatory genes, transcripts, and Expressed Sequence Tags (ESTs)[9, 10]. Until recently large scale SNP discovery in plants was limited to 
maize, Arabidopsis, and rice [11-15]. Genetic applications such as linkage mapping, population structure, association studies, map-based cloning, marker-assisted plant breeding, and functional genomics continue to 
be enabled by access to large collections of SNPs. Arabidopsis thaliana 
was the first plant genome sequenced [16] followed soon after by rice [17, 
18]. In the year 2011 alone, the number of plant genomes sequenced doubled as compared to the number sequenced in the previous decade, resulting in currently, 31 and counting, publicly released sequenced plant genomes (https://www.phytozome.net/). With the ever increasing throughput 
of next-generation sequencing (NGS), de novo and reference-based SNP 
discovery and application are now feasible for numerous plant species.},
	booktitle = {Crop {Breeding}},
	publisher = {Apple Academic Press},
	author = {Kumar, Santosh and Banks, Travis W. and Cloutier, Sylvie},
	year = {2016},
	note = {Num Pages: 36},
}

@article{derrien_fast_2012,
	title = {Fast {Computation} and {Applications} of {Genome} {Mappability}},
	volume = {7},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0030377},
	doi = {10.1371/journal.pone.0030377},
	abstract = {We present a fast mapping-based algorithm to compute the mappability of each region of a reference genome up to a specified number of mismatches. Knowing the mappability of a genome is crucial for the interpretation of massively parallel sequencing experiments. We investigate the properties of the mappability of eukaryotic DNA/RNA both as a whole and at the level of the gene family, providing for various organisms tracks which allow the mappability information to be visually explored. In addition, we show that mappability varies greatly between species and gene classes. Finally, we suggest several practical applications where mappability can be used to refine the analysis of high-throughput sequencing data (SNP calling, gene expression quantification and paired-end experiments). This work highlights mappability as an important concept which deserves to be taken into full account, in particular when massively parallel sequencing technologies are employed. The GEM mappability program belongs to the GEM (GEnome Multitool) suite of programs, which can be freely downloaded for any use from its website (http://gemlibrary.sourceforge.net).},
	language = {en},
	number = {1},
	urldate = {2024-05-26},
	journal = {PLOS ONE},
	author = {Derrien, Thomas and Estellé, Jordi and Sola, Santiago Marco and Knowles, David G. and Raineri, Emanuele and Guigó, Roderic and Ribeca, Paolo},
	month = jan,
	year = {2012},
	note = {Publisher: Public Library of Science},
	keywords = {Approximation methods, Exon mapping, Genome sequencing, Genomics, Human genomics, Invertebrate genomics, Mammalian genomics, Transcriptome analysis},
	pages = {e30377},
}

@article{audano_characterizing_2019,
	title = {Characterizing the {Major} {Structural} {Variant} {Alleles} of the {Human} {Genome}},
	volume = {176},
	issn = {00928674},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867418316337},
	doi = {10.1016/j.cell.2018.12.019},
	abstract = {In order to provide a comprehensive resource for human structural variants (SVs), we generated longread sequence data and analyzed SVs for ﬁfteen human genomes. We sequence resolved 99,604 insertions, deletions, and inversions including 2,238 (1.6 Mbp) that are shared among all discovery genomes with an additional 13,053 (6.9 Mbp) present in the majority, indicating minor alleles or errors in the reference. Genotyping in 440 additional genomes conﬁrms the most common SVs in unique euchromatin are now sequence resolved. We report a ninefold SV bias toward the last 5 Mbp of human chromosomes with nearly 55\% of all VNTRs (variable number of tandem repeats) mapping to this portion of the genome. We identify SVs affecting coding and noncoding regulatory loci improving annotation and interpretation of functional variation. These data provide the framework to construct a canonical human reference and a resource for developing advanced representations capable of capturing allelic diversity.},
	language = {en},
	number = {3},
	urldate = {2024-05-26},
	journal = {Cell},
	author = {Audano, Peter A. and Sulovari, Arvis and Graves-Lindsay, Tina A. and Cantsilieris, Stuart and Sorensen, Melanie and Welch, AnneMarie E. and Dougherty, Max L. and Nelson, Bradley J. and Shah, Ankeeta and Dutcher, Susan K. and Warren, Wesley C. and Magrini, Vincent and McGrath, Sean D. and Li, Yang I. and Wilson, Richard K. and Eichler, Evan E.},
	month = jan,
	year = {2019},
	pages = {663--675.e19},
}

@article{pabinger_survey_2014,
	title = {A survey of tools for variant analysis of next-generation genome sequencing data},
	volume = {15},
	issn = {1467-5463},
	url = {https://doi.org/10.1093/bib/bbs086},
	doi = {10.1093/bib/bbs086},
	abstract = {Recent advances in genome sequencing technologies provide unprecedented opportunities to characterize individual genomic landscapes and identify mutations relevant for diagnosis and therapy. Specifically, whole-exome sequencing using next-generation sequencing (NGS) technologies is gaining popularity in the human genetics community due to the moderate costs, manageable data amounts and straightforward interpretation of analysis results. While whole-exome and, in the near future, whole-genome sequencing are becoming commodities, data analysis still poses significant challenges and led to the development of a plethora of tools supporting specific parts of the analysis workflow or providing a complete solution. Here, we surveyed 205 tools for whole-genome/whole-exome sequencing data analysis supporting five distinct analytical steps: quality assessment, alignment, variant identification, variant annotation and visualization. We report an overview of the functionality, features and specific requirements of the individual tools. We then selected 32 programs for variant identification, variant annotation and visualization, which were subjected to hands-on evaluation using four data sets: one set of exome data from two patients with a rare disease for testing identification of germline mutations, two cancer data sets for testing variant callers for somatic mutations, copy number variations and structural variations, and one semi-synthetic data set for testing identification of copy number variations. Our comprehensive survey and evaluation of NGS tools provides a valuable guideline for human geneticists working on Mendelian disorders, complex diseases and cancers.},
	number = {2},
	urldate = {2024-05-26},
	journal = {Briefings in Bioinformatics},
	author = {Pabinger, Stephan and Dander, Andreas and Fischer, Maria and Snajder, Rene and Sperk, Michael and Efremova, Mirjana and Krabichler, Birgit and Speicher, Michael R. and Zschocke, Johannes and Trajanoski, Zlatko},
	month = mar,
	year = {2014},
	pages = {256--278},
}

@article{mccormack_applications_2013,
	series = {Morris {Goodman} {Memorial} {Symposium}},
	title = {Applications of next-generation sequencing to phylogeography and phylogenetics},
	volume = {66},
	issn = {1055-7903},
	url = {https://www.sciencedirect.com/science/article/pii/S1055790311005203},
	doi = {10.1016/j.ympev.2011.12.007},
	abstract = {This is a time of unprecedented transition in DNA sequencing technologies. Next-generation sequencing (NGS) clearly holds promise for fast and cost-effective generation of multilocus sequence data for phylogeography and phylogenetics. However, the focus on non-model organisms, in addition to uncertainty about which sample preparation methods and analyses are appropriate for different research questions and evolutionary timescales, have contributed to a lag in the application of NGS to these fields. Here, we outline some of the major obstacles specific to the application of NGS to phylogeography and phylogenetics, including the focus on non-model organisms, the necessity of obtaining orthologous loci in a cost-effective manner, and the predominate use of gene trees in these fields. We describe the most promising methods of sample preparation that address these challenges. Methods that reduce the genome by restriction digest and manual size selection are most appropriate for studies at the intraspecific level, whereas methods that target specific genomic regions (i.e., target enrichment or sequence capture) have wider applicability from the population level to deep-level phylogenomics. Additionally, we give an overview of how to analyze NGS data to arrive at data sets applicable to the standard toolkit of phylogeography and phylogenetics, including initial data processing to alignment and genotype calling (both SNPs and loci involving many SNPs). Even though whole-genome sequencing is likely to become affordable rather soon, because phylogeography and phylogenetics rely on analysis of hundreds of individuals in many cases, methods that reduce the genome to a subset of loci should remain more cost-effective for some time to come.},
	number = {2},
	urldate = {2024-05-26},
	journal = {Molecular Phylogenetics and Evolution},
	author = {McCormack, John E. and Hird, Sarah M. and Zellmer, Amanda J. and Carstens, Bryan C. and Brumfield, Robb T.},
	month = feb,
	year = {2013},
	keywords = {Coalescence, High-throughput sequencing, Population genomics, Reduced representation library, Target enrichment},
	pages = {526--538},
}

@article{branstetter_enriching_2017,
	title = {Enriching the ant tree of life: enhanced {UCE} bait set for genome-scale phylogenetics of ants and other {Hymenoptera}},
	volume = {8},
	copyright = {© 2017 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society},
	issn = {2041-210X},
	shorttitle = {Enriching the ant tree of life},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12742},
	doi = {10.1111/2041-210X.12742},
	abstract = {Targeted enrichment of conserved genomic regions (e.g. ultraconserved elements or UCEs) has emerged as a promising tool for inferring evolutionary history in many organismal groups. Because the UCE approach is still relatively new, much remains to be learned about how best to identify UCE loci and design baits to enrich them. We test an updated UCE identification and bait design workflow for the insect order Hymenoptera, with a particular focus on ants. The new strategy augments a previous bait design for Hymenoptera by (i) changing the parameters by which conserved genomic regions are identified and retained, and (ii) increasing the number of genomes used for locus identification and bait design. We perform in vitro validation of the approach in ants by synthesizing an ant-specific bait set that targets UCE loci and a set of ‘legacy’ phylogenetic markers. Using this bait set, we generate new data for 84 taxa (16/17 ant subfamilies) and extract loci from an additional 17 genome-enabled taxa. We then use these data to examine UCE capture success and phylogenetic performance across ants. We also test the workability of extracting legacy markers from enriched samples and combining the data with published datasets. The updated bait design (hym-v2) contained a total of 2590-targeted UCE loci for Hymenoptera, significantly increasing the number of loci relative to the original bait set (hym-v1; 1510 loci). Across 38 genome-enabled Hymenoptera and 84 enriched samples, experiments demonstrated a high and unbiased capture success rate, with the mean locus enrichment rate being 2214 loci per sample. Phylogenomic analyses of ants produced a robust tree that included strong support for previously uncertain relationships. Complementing the UCE results, we successfully enriched legacy markers, combined the data with published Sanger datasets and generated a comprehensive ant phylogeny containing 1060 terminals. Overall, the new UCE bait design strategy resulted in an enhanced bait set for genome-scale phylogenetics in ants and other Hymenoptera. Our in vitro tests demonstrate the utility of the updated design workflow, providing evidence that this approach could be applied to any organismal group with available genomic information.},
	language = {en},
	number = {6},
	urldate = {2024-05-26},
	journal = {Methods in Ecology and Evolution},
	author = {Branstetter, Michael G. and Longino, John T. and Ward, Philip S. and Faircloth, Brant C.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12742},
	keywords = {Formicidae, molecular systematics, next-generation sequencing, phylogenomics, targeted enrichment, ultraconserved elements},
	pages = {768--776},
}

@article{delsuc_phylogenomics_2005,
	title = {Phylogenomics and the reconstruction of the tree of life},
	volume = {6},
	copyright = {2005 Springer Nature Limited},
	issn = {1471-0064},
	url = {https://www.nature.com/articles/nrg1603},
	doi = {10.1038/nrg1603},
	abstract = {Understanding phylogenetic relationships among organisms is a prerequisite of evolutionary studies, as contemporary species all share a common history through their ancestry.The wealth of sequence data generated by large-scale genome projects is transforming phylogenetics — the reconstruction of evolutionary history — into phylogenomics.Traditional sequence-based methods of phylogenetic reconstruction (supermatrix and supertree approaches) can also be used at the genome level.New methods based on whole-genome features are also currently being developed to infer phylogenomic trees.Recent studies have revealed the potential of phylogenomic methods for answering long-standing phylogenetic questions.The supermatrix approach that analyses the concatenation of multiple gene sequences is the best-characterized method. Its potential relies on the increased resolving power provided by the use of a large number of sequence positions, which reduces the sampling error.Including large amounts of data in phylogenomic analyses increases the possibility of obtaining highly supported but incorrect phylogenetic results that are due to inconsistency — that is, the convergence towards an incorrect solution as more data are added.Inconsistency arises because current phylogenetic reconstruction methods do not account for the full complexity of the molecular evolutionary process in their underlying assumptions.The risks of inconsistency in phylogenomics analyses can be reduced by the development of better models of sequence evolution, by the critical evaluation of data properties and by the use of only the most reliable characters.Corroboration of phylogenomic results is an important issue, as whole genomes represent the ultimate source of phylogenetically informative characters. Sources of corroboration include the congruence of results obtained using different phylogenomic methods, and their robustness to taxon sampling.The very nature of the evolutionary process and the limitations of current phylogenetic reconstruction methods imply that parts of the tree of life might prove difficult, if not impossible, to resolve with confidence.},
	language = {en},
	number = {5},
	urldate = {2024-05-26},
	journal = {Nature Reviews Genetics},
	author = {Delsuc, Frédéric and Brinkmann, Henner and Philippe, Hervé},
	month = may,
	year = {2005},
	note = {Publisher: Nature Publishing Group},
	keywords = {Agriculture, Animal Genetics and Genomics, Biomedicine, Cancer Research, Gene Function, Human Genetics, general},
	pages = {361--375},
}

@article{simossis_homology-extended_2005,
	title = {Homology-extended sequence alignment},
	volume = {33},
	issn = {0305-1048},
	url = {https://doi.org/10.1093/nar/gki233},
	doi = {10.1093/nar/gki233},
	abstract = {We present a profile–profile multiple alignment strategy that uses database searching to collect homologues for each sequence in a given set, in order to enrich their available evolutionary information for the alignment. For each of the alignment sequences, the putative homologous sequences that score above a pre-defined threshold are incorporated into a position-specific pre-alignment profile. The enriched position-specific profile is used for standard progressive alignment, thereby more accurately describing the characteristic features of the given sequence set. We show that owing to the incorporation of the pre-alignment information into a standard progressive multiple alignment routine, the alignment quality between distant sequences increases significantly and outperforms state-of-the-art methods, such as T-COFFEE and MUSCLE. We also show that although entirely sequence-based, our novel strategy is better at aligning distant sequences when compared with a recent contact-based alignment method. Therefore, our pre-alignment profile strategy should be advantageous for applications that rely on high alignment accuracy such as local structure prediction, comparative modelling and threading.},
	number = {3},
	urldate = {2024-05-26},
	journal = {Nucleic Acids Research},
	author = {Simossis, V. A. and Kleinjung, J. and Heringa, J.},
	month = feb,
	year = {2005},
	pages = {816--824},
}

@article{sexton_homology-based_2016,
	title = {Homology-{Based} {Identification} of a {Mutation} in the {Coronavirus} {RNA}-{Dependent} {RNA} {Polymerase} {That} {Confers} {Resistance} to {Multiple} {Mutagens}},
	volume = {90},
	url = {https://journals.asm.org/doi/full/10.1128/jvi.00080-16},
	doi = {10.1128/jvi.00080-16},
	abstract = {Positive-sense RNA viruses encode RNA-dependent RNA polymerases (RdRps) essential for genomic replication. With the exception of the large nidoviruses, such as coronaviruses (CoVs), RNA viruses lack proofreading and thus are dependent on RdRps to control nucleotide selectivity and fidelity. CoVs encode a proofreading exonuclease in nonstructural protein 14 (nsp14-ExoN), which confers a greater-than-10-fold increase in fidelity compared to other RNA viruses. It is unknown to what extent the CoV polymerase (nsp12-RdRp) participates in replication fidelity. We sought to determine whether homology modeling could identify putative determinants of nucleotide selectivity and fidelity in CoV RdRps. We modeled the CoV murine hepatitis virus (MHV) nsp12-RdRp structure and superimposed it on solved picornaviral RdRp structures. Fidelity-altering mutations previously identified in coxsackie virus B3 (CVB3) were mapped onto the nsp12-RdRp model structure and then engineered into the MHV genome with [nsp14-ExoN(+)] or without [nsp14-ExoN(−)] ExoN activity. Using this method, we identified two mutations conferring resistance to the mutagen 5-fluorouracil (5-FU): nsp12-M611F and nsp12-V553I. For nsp12-V553I, we also demonstrate resistance to the mutagen 5-azacytidine (5-AZC) and decreased accumulation of mutations. Resistance to 5-FU, and a decreased number of genomic mutations, was effectively masked by nsp14-ExoN proofreading activity. These results indicate that nsp12-RdRp likely functions in fidelity regulation and that, despite low sequence conservation, some determinants of RdRp nucleotide selectivity are conserved across RNA viruses. The results also indicate that, with regard to nucleotide selectivity, nsp14-ExoN is epistatic to nsp12-RdRp, consistent with its proposed role in a multiprotein replicase-proofreading complex.
IMPORTANCE RNA viruses have evolutionarily fine-tuned replication fidelity to balance requirements for genetic stability and diversity. Responsibility for replication fidelity in RNA viruses has been attributed to the RNA-dependent RNA polymerases, with mutations in RdRps for multiple RNA viruses shown to alter fidelity and attenuate virus replication and virulence. Coronaviruses (CoVs) are the only known RNA viruses to encode a proofreading exonuclease (nsp14-ExoN), as well as other replicase proteins involved in regulation of fidelity. This report shows that the CoV RdRp (nsp12) likely functions in replication fidelity; that residue determinants of CoV RdRp nucleotide selectivity map to similar structural regions of other, unrelated RNA viral polymerases; and that for CoVs, the proofreading activity of the nsp14-ExoN is epistatic to the function of the RdRp in fidelity.},
	number = {16},
	urldate = {2024-05-26},
	journal = {Journal of Virology},
	author = {Sexton, Nicole R. and Smith, Everett Clinton and Blanc, Hervé and Vignuzzi, Marco and Peersen, Olve B. and Denison, Mark R.},
	month = jul,
	year = {2016},
	note = {Publisher: American Society for Microbiology},
	pages = {7415--7428},
}

@article{kim_cross-species_2020,
	title = {Cross-species oncogenic signatures of breast cancer in canine mammary tumors},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-17458-0},
	doi = {10.1038/s41467-020-17458-0},
	abstract = {Genomic and precision medicine research has afforded notable advances in human cancer treatment, yet applicability to other species remains uncertain. Through whole-exome and transcriptome analyses of 191 spontaneous canine mammary tumors (CMTs) that exhibit the archetypal features of human breast cancers, we found a striking resemblance of genomic characteristics including frequent PIK3CA mutations (43.1\%), aberrations of the PI3K-Akt pathway (61.7\%), and key genes involved in cancer initiation and progression. We also identified three gene expression-based CMT subtypes, one of which segregated with basal-like human breast cancer subtypes with activated epithelial-to-mesenchymal transition, low claudin expression, and unfavorable disease prognosis. A relative lack of ERBB2 amplification and Her2-enrichment subtype in CMT denoted species-specific molecular mechanisms. Taken together, our results elucidate cross-species oncogenic signatures for a better understanding of universal and context-dependent mechanisms in breast cancer development and provide a basis for precision diagnostics and therapeutics for domestic dogs.},
	language = {en},
	number = {1},
	urldate = {2024-05-26},
	journal = {Nature Communications},
	author = {Kim, Tae-Min and Yang, In Seok and Seung, Byung-Joon and Lee, Sejoon and Kim, Dohyun and Ha, Yoo-Jin and Seo, Mi-kyoung and Kim, Ka-Kyung and Kim, Hyun Seok and Cheong, Jae-Ho and Sur, Jung-Hyang and Nam, Hojung and Kim, Sangwoo},
	month = jul,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	keywords = {Breast cancer, Cancer genomics, Genome informatics},
	pages = {3616},
}

@article{he_comprehensive_2021,
	title = {Comprehensive fundamental somatic variant calling and quality management strategies for human cancer genomes},
	volume = {22},
	issn = {1477-4054},
	url = {https://doi.org/10.1093/bib/bbaa083},
	doi = {10.1093/bib/bbaa083},
	abstract = {Next-generation sequencing (NGS) technology has revolutionised human cancer research, particularly via detection of genomic variants with its ultra-high-throughput sequencing and increasing affordability. However, the inundation of rich cancer genomics data has resulted in significant challenges in its exploration and translation into biological insights. One of the difficulties in cancer genome sequencing is software selection. Currently, multiple tools are widely used to process NGS data in four stages: raw sequence data pre-processing and quality control (QC), sequence alignment, variant calling and annotation and visualisation. However, the differences between these NGS tools, including their installation, merits, drawbacks and application, have not been fully appreciated. Therefore, a systematic review of the functionality and performance of NGS tools is required to provide cancer researchers with guidance on software and strategy selection. Another challenge is the multidimensional QC of sequencing data because QC can not only report varied sequence data characteristics but also reveal deviations in diverse features and is essential for a meaningful and successful study. However, monitoring of QC metrics in specific steps including alignment and variant calling is neglected in certain pipelines such as the ‘Best Practices Workflows’ in GATK. In this review, we investigated the most widely used software for the fundamental analysis and QC of cancer genome sequencing data and provided instructions for selecting the most appropriate software and pipelines to ensure precise and efficient conclusions. We further discussed the prospects and new research directions for cancer genomics.},
	number = {3},
	urldate = {2024-05-26},
	journal = {Briefings in Bioinformatics},
	author = {He, Xiaoyu and Chen, Shanyu and Li, Ruilin and Han, Xinyin and He, Zhipeng and Yuan, Danyang and Zhang, Shuying and Duan, Xiaohong and Niu, Beifang},
	month = may,
	year = {2021},
	pages = {bbaa083},
}

@article{meyerson_advances_2010,
	title = {Advances in understanding cancer genomes through second-generation sequencing},
	volume = {11},
	copyright = {2010 Springer Nature Limited},
	issn = {1471-0064},
	url = {https://www.nature.com/articles/nrg2841},
	doi = {10.1038/nrg2841},
	abstract = {Analyses of cancer genome sequences and structures provide insights for understanding cancer biology, diagnosis and therapy.The application of second-generation DNA sequencing technologies (also known as next-generation sequencing) is allowing substantial advances in cancer genomics. In recent years, it has become feasible to sequence the expressed genes ('transcriptomes'), known exons ('exomes'), and complete genomes of cancer samples.There are particular challenges for the detection and diagnosis of cancer genome alterations. For example, some cancer genome alterations are prevalent at low frequency in clinical samples, often owing to substantial admixture with non-malignant cells.The large quantity of data from second-generation sequencing provides statistical and computational challenges.An impetus for studies of somatic genome alterations is the potential for therapies targeted against the products of these alterations.},
	language = {en},
	number = {10},
	urldate = {2024-05-26},
	journal = {Nature Reviews Genetics},
	author = {Meyerson, Matthew and Gabriel, Stacey and Getz, Gad},
	month = oct,
	year = {2010},
	note = {Publisher: Nature Publishing Group},
	keywords = {Cancer genomics, Next-generation sequencing},
	pages = {685--696},
}

@article{tamura_virological_2023,
	title = {Virological characteristics of the {SARS}-{CoV}-2 {XBB} variant derived from recombination of two {Omicron} subvariants},
	volume = {14},
	copyright = {2023 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-023-38435-3},
	doi = {10.1038/s41467-023-38435-3},
	abstract = {In late 2022, SARS-CoV-2 Omicron subvariants have become highly diversified, and XBB is spreading rapidly around the world. Our phylogenetic analyses suggested that XBB emerged through the recombination of two cocirculating BA.2 lineages, BJ.1 and BM.1.1.1 (a progeny of BA.2.75), during the summer of 2022. XBB.1 is the variant most profoundly resistant to BA.2/5 breakthrough infection sera to date and is more fusogenic than BA.2.75. The recombination breakpoint is located in the receptor-binding domain of spike, and each region of the recombinant spike confers immune evasion and increases fusogenicity. We further provide the structural basis for the interaction between XBB.1 spike and human ACE2. Finally, the intrinsic pathogenicity of XBB.1 in male hamsters is comparable to or even lower than that of BA.2.75. Our multiscale investigation provides evidence suggesting that XBB is the first observed SARS-CoV-2 variant to increase its fitness through recombination rather than substitutions.},
	language = {en},
	number = {1},
	urldate = {2024-05-26},
	journal = {Nature Communications},
	author = {Tamura, Tomokazu and Ito, Jumpei and Uriu, Keiya and Zahradnik, Jiri and Kida, Izumi and Anraku, Yuki and Nasser, Hesham and Shofa, Maya and Oda, Yoshitaka and Lytras, Spyros and Nao, Naganori and Itakura, Yukari and Deguchi, Sayaka and Suzuki, Rigel and Wang, Lei and Begum, MST Monira and Kita, Shunsuke and Yajima, Hisano and Sasaki, Jiei and Sasaki-Tabata, Kaori and Shimizu, Ryo and Tsuda, Masumi and Kosugi, Yusuke and Fujita, Shigeru and Pan, Lin and Sauter, Daniel and Yoshimatsu, Kumiko and Suzuki, Saori and Asakura, Hiroyuki and Nagashima, Mami and Sadamasu, Kenji and Yoshimura, Kazuhisa and Yamamoto, Yuki and Nagamoto, Tetsuharu and Schreiber, Gideon and Maenaka, Katsumi and Hashiguchi, Takao and Ikeda, Terumasa and Fukuhara, Takasuke and Saito, Akatsuki and Tanaka, Shinya and Matsuno, Keita and Takayama, Kazuo and Sato, Kei},
	month = may,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {SARS-CoV-2, Viral evolution, Virus–host interactions},
	pages = {2800},
}

@article{lang_identification_2022,
	title = {Identification of neoantigens for individualized therapeutic cancer vaccines},
	volume = {21},
	copyright = {2022 Springer Nature Limited},
	issn = {1474-1784},
	url = {https://www.nature.com/articles/s41573-021-00387-y},
	doi = {10.1038/s41573-021-00387-y},
	abstract = {Somatic mutations in cancer cells can generate tumour-specific neoepitopes, which are recognized by autologous T cells in the host. As neoepitopes are not subject to central immune tolerance and are not expressed in healthy tissues, they are attractive targets for therapeutic cancer vaccines. Because the vast majority of cancer mutations are unique to the individual patient, harnessing the full potential of this rich source of targets requires individualized treatment approaches. Many computational algorithms and machine-learning tools have been developed to identify mutations in sequence data, to prioritize those that are more likely to be recognized by T cells and to design tailored vaccines for every patient. In this Review, we fill the gaps between the understanding of basic mechanisms of T cell recognition of neoantigens and the computational approaches for discovery of somatic mutations and neoantigen prediction for cancer immunotherapy. We present a new classification of neoantigens, distinguishing between guarding, restrained and ignored neoantigens, based on how they confer proficient antitumour immunity in a given clinical context. Such context-based differentiation will contribute to a framework that connects neoantigen biology to the clinical setting and medical peculiarities of cancer, and will enable future neoantigen-based therapies to provide greater clinical benefit.},
	language = {en},
	number = {4},
	urldate = {2024-05-26},
	journal = {Nature Reviews Drug Discovery},
	author = {Lang, Franziska and Schrörs, Barbara and Löwer, Martin and Türeci, Oezlem and Sahin, Ugur},
	month = apr,
	year = {2022},
	keywords = {Cancer genomics, Predictive medicine, Tumour biomarkers},
	pages = {261--282},
}

@article{hu_next-generation_2021,
	series = {Next {Generation} {Sequencing} and its {Application} to {Medical} {Laboratory} {Immunology}},
	title = {Next-generation sequencing technologies: {An} overview},
	volume = {82},
	issn = {0198-8859},
	shorttitle = {Next-generation sequencing technologies},
	url = {https://www.sciencedirect.com/science/article/pii/S0198885921000628},
	doi = {10.1016/j.humimm.2021.02.012},
	abstract = {Since the days of Sanger sequencing, next-generation sequencing technologies have significantly evolved to provide increased data output, efficiencies, and applications. These next generations of technologies can be categorized based on read length. This review provides an overview of these technologies as two paradigms: short-read, or “second-generation,” technologies, and long-read, or “third-generation,” technologies. Herein, short-read sequencing approaches are represented by the most prevalent technologies, Illumina and Ion Torrent, and long-read sequencing approaches are represented by Pacific Biosciences and Oxford Nanopore technologies. All technologies are reviewed along with reported advantages and disadvantages. Until recently, short-read sequencing was thought to provide high accuracy limited by read-length, while long-read technologies afforded much longer read-lengths at the expense of accuracy. Emerging developments for third-generation technologies hold promise for the next wave of sequencing evolution, with the co-existence of longer read lengths and high accuracy.},
	number = {11},
	urldate = {2024-05-26},
	journal = {Human Immunology},
	author = {Hu, Taishan and Chitnis, Nilesh and Monos, Dimitri and Dinh, Anh},
	month = nov,
	year = {2021},
	keywords = {Long-read sequencing, Next-generation sequencing, Short-read sequencing},
	pages = {801--811},
}

@article{huffman_method_1952,
	title = {A {Method} for the {Construction} of {Minimum}-{Redundancy} {Codes}},
	volume = {40},
	issn = {2162-6634},
	url = {https://ieeexplore.ieee.org/abstract/document/4051119?casa_token=PQmK8Fl0oV0AAAAA:d9eNzHPI2IkXxAOYnLSQ37HH1mmUFEP3_dMm99oKrUhUOfTkWFFp5YuMBCOdVQvDPR1UE7uvow},
	doi = {10.1109/JRPROC.1952.273898},
	abstract = {An optimum method of coding an ensemble of messages consisting of a finite number of members is developed. A minimum-redundancy code is one constructed in such a way that the average number of coding digits per message is minimized.},
	number = {9},
	urldate = {2024-05-24},
	journal = {Proceedings of the IRE},
	author = {Huffman, David A.},
	month = sep,
	year = {1952},
	keywords = {Transmitters},
	pages = {1098--1101},
}

@article{ziv_universal_1977,
	title = {A universal algorithm for sequential data compression},
	volume = {23},
	issn = {1557-9654},
	url = {https://ieeexplore.ieee.org/abstract/document/1055714?casa_token=o6sVfpkK0zsAAAAA:N2n0bMKmOGCfeeTa-y-ER_qXHROSJwrTQn1FsCKWHryfwcLW3kwwJKg1CnUCgO8aHohDf-5SqQ},
	doi = {10.1109/TIT.1977.1055714},
	abstract = {A universal algorithm for sequential data compression is presented. Its performance is investigated with respect to a nonprobabilistic model of constrained sources. The compression ratio achieved by the proposed universal code uniformly approaches the lower bounds on the compression ratios attainable by block-to-variable codes and variable-to-block codes designed to match a completely specified source.},
	number = {3},
	urldate = {2024-05-24},
	journal = {IEEE Transactions on Information Theory},
	author = {Ziv, J. and Lempel, A.},
	month = may,
	year = {1977},
	pages = {337--343},
}

@article{hach_deez_2014,
	title = {{DeeZ}: reference-based compression by local assembly},
	volume = {11},
	copyright = {2014 Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{DeeZ}},
	url = {https://www.nature.com/articles/nmeth.3133},
	doi = {10.1038/nmeth.3133},
	language = {en},
	number = {11},
	urldate = {2024-05-19},
	journal = {Nature Methods},
	author = {Hach, Faraz and Numanagic, Ibrahim and Sahinalp, S. Cenk},
	month = nov,
	year = {2014},
	note = {Publisher: Nature Publishing Group},
	keywords = {Data publication and archiving},
	pages = {1082--1084},
}

@article{fritz_efficient_2011,
	title = {Efficient storage of high throughput {DNA} sequencing data using reference-based compression},
	volume = {21},
	issn = {1088-9051, 1549-5469},
	url = {https://genome.cshlp.org/content/21/5/734},
	doi = {10.1101/gr.114819.110},
	abstract = {Data storage costs have become an appreciable proportion of total cost in the creation and analysis of DNA sequence data. Of particular concern is that the rate of increase in DNA sequencing is significantly outstripping the rate of increase in disk storage capacity. In this paper we present a new reference-based compression method that efficiently compresses DNA sequences for storage. Our approach works for resequencing experiments that target well-studied genomes. We align new sequences to a reference genome and then encode the differences between the new sequence and the reference genome for storage. Our compression method is most efficient when we allow controlled loss of data in the saving of quality information and unaligned sequences. With this new compression method we observe exponential efficiency gains as read lengths increase, and the magnitude of this efficiency gain can be controlled by changing the amount of quality information stored. Our compression method is tunable: The storage of quality scores and unaligned sequences may be adjusted for different experiments to conserve information or to minimize storage costs, and provides one opportunity to address the threat that increasing DNA sequence volumes will overcome our ability to store the sequences.},
	language = {en},
	number = {5},
	urldate = {2024-05-19},
	journal = {Genome Research},
	author = {Fritz, Markus Hsi-Yang and Leinonen, Rasko and Cochrane, Guy and Birney, Ewan},
	month = may,
	year = {2011},
	pmid = {21245279},
	note = {Company: Cold Spring Harbor Laboratory Press
Distributor: Cold Spring Harbor Laboratory Press
Institution: Cold Spring Harbor Laboratory Press
Label: Cold Spring Harbor Laboratory Press
Publisher: Cold Spring Harbor Lab},
	pages = {734--740},
}

@article{popitsch_ngc_2013,
	title = {{NGC}: lossless and lossy compression of aligned high-throughput sequencing data},
	volume = {41},
	issn = {0305-1048},
	shorttitle = {{NGC}},
	url = {https://doi.org/10.1093/nar/gks939},
	doi = {10.1093/nar/gks939},
	abstract = {A major challenge of current high-throughput sequencing experiments is not only the generation of the sequencing data itself but also their processing, storage and transmission. The enormous size of these data motivates the development of data compression algorithms usable for the implementation of the various storage policies that are applied to the produced intermediate and final result files. In this article, we present NGC, a tool for the compression of mapped short read data stored in the wide-spread SAM format. NGC enables lossless and lossy compression and introduces the following two novel ideas: first, we present a way to reduce the number of required code words by exploiting common features of reads mapped to the same genomic positions; second, we present a highly configurable way for the quantization of per-base quality values, which takes their influence on downstream analyses into account. NGC, evaluated with several real-world data sets, saves 33–66\% of disc space using lossless and up to 98\% disc space using lossy compression. By applying two popular variant and genotype prediction tools to the decompressed data, we could show that the lossy compression modes preserve \&gt;99\% of all called variants while outperforming comparable methods in some configurations.},
	number = {1},
	urldate = {2024-05-19},
	journal = {Nucleic Acids Research},
	author = {Popitsch, Niko and von Haeseler, Arndt},
	month = jan,
	year = {2013},
	pages = {e27},
}

@article{campagne_compression_2013,
	title = {Compression of {Structured} {High}-{Throughput} {Sequencing} {Data}},
	volume = {8},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079871},
	doi = {10.1371/journal.pone.0079871},
	abstract = {Large biological datasets are being produced at a rapid pace and create substantial storage challenges, particularly in the domain of high-throughput sequencing (HTS). Most approaches currently used to store HTS data are either unable to quickly adapt to the requirements of new sequencing or analysis methods (because they do not support schema evolution), or fail to provide state of the art compression of the datasets. We have devised new approaches to store HTS data that support seamless data schema evolution and compress datasets substantially better than existing approaches. Building on these new approaches, we discuss and demonstrate how a multi-tier data organization can dramatically reduce the storage, computational and network burden of collecting, analyzing, and archiving large sequencing datasets. For instance, we show that spliced RNA-Seq alignments can be stored in less than 4\% the size of a BAM file with perfect data fidelity. Compared to the previous compression state of the art, these methods reduce dataset size more than 40\% when storing exome, gene expression or DNA methylation datasets. The approaches have been integrated in a comprehensive suite of software tools (http://goby.campagnelab.org) that support common analyses for a range of high-throughput sequencing assays.},
	language = {en},
	number = {11},
	urldate = {2024-05-19},
	journal = {PLOS ONE},
	author = {Campagne, Fabien and Dorff, Kevin C. and Chambwe, Nyasha and Robinson, James T. and Mesirov, Jill P.},
	month = nov,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Arithmetic, Compression, Computer software, Data compression, Data management, Genomics, Multiple alignment calculation, Sequence alignment},
	pages = {e79871},
}

@article{hosseini_survey_2016,
	title = {A {Survey} on {Data} {Compression} {Methods} for {Biological} {Sequences}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/7/4/56},
	doi = {10.3390/info7040056},
	abstract = {The ever increasing growth of the production of high-throughput sequencing data poses a serious challenge to the storage, processing and transmission of these data. As frequently stated, it is a data deluge. Compression is essential to address this challenge—it reduces storage space and processing costs, along with speeding up data transmission. In this paper, we provide a comprehensive survey of existing compression approaches, that are specialized for biological data, including protein and DNA sequences. Also, we devote an important part of the paper to the approaches proposed for the compression of different file formats, such as FASTA, as well as FASTQ and SAM/BAM, which contain quality scores and metadata, in addition to the biological sequences. Then, we present a comparison of the performance of several methods, in terms of compression ratio, memory usage and compression/decompression time. Finally, we present some suggestions for future research on biological data compression.},
	language = {en},
	number = {4},
	urldate = {2024-05-19},
	journal = {Information},
	author = {Hosseini, Morteza and Pratas, Diogo and Pinho, Armando J.},
	month = dec,
	year = {2016},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {BAM, DNA sequence, FASTA, FASTQ, Multi-FASTA, SAM, protein sequence, reference-based compression, reference-free compression},
	pages = {56},
}

@misc{banerjee_abridge_2022,
	title = {{ABRIDGE}: {An} ultra-compression software for {SAM} alignment files},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	shorttitle = {{ABRIDGE}},
	url = {https://www.biorxiv.org/content/10.1101/2022.01.04.474935v1},
	doi = {10.1101/2022.01.04.474935},
	abstract = {Advancement in technology has enabled sequencing machines to produce vast amounts of genetic data, causing an increase in storage demands. Most genomic software utilizes read alignments for several purposes including transcriptome assembly and gene count estimation. Herein we present, ABRIDGE, a state-of-the-art compressor for SAM alignment files offering users both lossless and lossy compression options. This reference-based file compressor achieves the best compression ratio among all compression software ensuring lower space demand and faster file transmission. Central to the software is a novel algorithm that retains non-redundant information. This new approach has allowed ABRIDGE to achieve a compression 16\% higher than the second-best compressor for RNA-Seq reads and over 35\% for DNA-Seq reads. ABRIDGE also offers users the option to randomly access location without having to decompress the entire file. ABRIDGE is distributed under MIT license and can be obtained from GitHub (https://github.com/sagnikbanerjee15/Abridge) and docker hub. We anticipate that the user community will adopt ABRIDGE within their existing pipeline encouraging further research in this domain.},
	language = {en},
	urldate = {2024-05-19},
	publisher = {bioRxiv},
	author = {Banerjee, Sagnik and Andorf, Carson},
	month = jan,
	year = {2022},
	note = {Pages: 2022.01.04.474935
Section: New Results},
}

@book{alexandrescu_d_2010,
	title = {The {D} {Programming} {Language}},
	isbn = {978-0-13-265440-1},
	abstract = {D is a programming language built to help programmers address the challenges of modern software development. It does so by fostering modules interconnected through precise interfaces, a federation of tightly integrated programming paradigms, language-enforced thread isolation, modular type safety, an efficient memory model, and more.   The D Programming Language is an authoritative and comprehensive introduction to D. Reflecting the author’s signature style, the writing is casual and conversational, but never at the expense of focus and pre¿cision. It covers all aspects of the language (such as expressions, statements, types, functions, contracts, and modules), but it is much more than an enumeration of features.   Inside the book you will find  In-depth explanations, with idiomatic examples, for all language features How feature groups support major programming paradigms Rationale and best-use advice for each major feature Discussion of cross-cutting issues, such as error handling, contract programming, and concurrency Tables, figures, and “cheat sheets” that serve as a handy quick reference for day-to-day problem solving with D  Written for the working programmer, The D Programming Language not only introduces the D language—it presents a compendium of good practices and idioms to help both your coding with D and your coding in general.},
	language = {en},
	publisher = {Addison-Wesley Professional},
	author = {Alexandrescu, Andrei},
	month = jun,
	year = {2010},
	note = {Google-Books-ID: bn7GNq6fiIUC},
	keywords = {Computers / Languages / C, Computers / Languages / General},
}

@misc{noauthor_novosort_nodate,
	title = {{NovoSort} {\textbar} {Novocraft}},
	url = {https://www.novocraft.com/products/novosort/},
	language = {en-US},
	urldate = {2024-05-19},
}

@article{the_bioconda_team_bioconda_2018,
	title = {Bioconda: sustainable and comprehensive software distribution for the life sciences},
	volume = {15},
	issn = {1548-7091, 1548-7105},
	shorttitle = {Bioconda},
	url = {https://www.nature.com/articles/s41592-018-0046-7},
	doi = {10.1038/s41592-018-0046-7},
	language = {en},
	number = {7},
	urldate = {2024-05-19},
	journal = {Nature Methods},
	author = {{The Bioconda Team} and Grüning, Björn and Dale, Ryan and Sjödin, Andreas and Chapman, Brad A. and Rowe, Jillian and Tomkins-Tinch, Christopher H. and Valieris, Renan and Köster, Johannes},
	month = jul,
	year = {2018},
	pages = {475--476},
}

@article{the_1000_genomes_project_consortium_1000_2012,
	title = {The 1000 {Genomes} {Project}: data management and community access},
	volume = {9},
	copyright = {https://creativecommons.org/licenses/by-nc-sa/3.0/},
	issn = {1548-7091, 1548-7105},
	shorttitle = {The 1000 {Genomes} {Project}},
	url = {https://www.nature.com/articles/nmeth.1974},
	doi = {10.1038/nmeth.1974},
	language = {en},
	number = {5},
	urldate = {2024-05-17},
	journal = {Nature Methods},
	author = {{The 1000 Genomes Project Consortium} and Clarke, Laura and Zheng-Bradley, Xiangqun and Smith, Richard and Kulesha, Eugene and Xiao, Chunlin and Toneva, Iliana and Vaughan, Brendan and Preuss, Don and Leinonen, Rasko and Shumway, Martin and Sherry, Stephen and Flicek, Paul},
	month = may,
	year = {2012},
	pages = {459--462},
}

@article{tarasov_sambamba_2015,
	title = {Sambamba: fast processing of {NGS} alignment formats},
	volume = {31},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1367-4811, 1367-4803},
	shorttitle = {Sambamba},
	url = {https://academic.oup.com/bioinformatics/article/31/12/2032/214758},
	doi = {10.1093/bioinformatics/btv098},
	abstract = {Abstract
            Summary: Sambamba is a high-performance robust tool and library for working with SAM, BAM and CRAM sequence alignment files; the most common file formats for aligned next generation sequencing data. Sambamba is a faster alternative to samtools that exploits multi-core processing and dramatically reduces processing time. Sambamba is being adopted at sequencing centers, not only because of its speed, but also because of additional functionality, including coverage analysis and powerful filtering capability.
            Availability and implementation: Sambamba is free and open source software, available under a GPLv2 license. Sambamba can be downloaded and installed from http://www.open-bio.org/wiki/Sambamba.
            Sambamba v0.5.0 was released with doi:10.5281/zenodo.13200.
            Contact: j.c.p.prins@umcutrecht.nl},
	language = {en},
	number = {12},
	urldate = {2024-05-06},
	journal = {Bioinformatics},
	author = {Tarasov, Artem and Vilella, Albert J. and Cuppen, Edwin and Nijman, Isaac J. and Prins, Pjotr},
	month = jun,
	year = {2015},
	keywords = {related},
	pages = {2032--2034},
}

@article{liu_sequence_2023,
	title = {Sequence {Alignment}/{Map} format: a comprehensive review of approaches and applications},
	volume = {24},
	issn = {1477-4054},
	shorttitle = {Sequence {Alignment}/{Map} format},
	url = {https://doi.org/10.1093/bib/bbad320},
	doi = {10.1093/bib/bbad320},
	abstract = {The Sequence Alignment/Map (SAM) format file is the text file used to record alignment information. Alignment is the core of sequencing analysis, and downstream tasks accept mapping results for further processing. Given the rapid development of the sequencing industry today, a comprehensive understanding of the SAM format and related tools is necessary to meet the challenges of data processing and analysis. This paper is devoted to retrieving knowledge in the broad field of SAM. First, the format of SAM is introduced to understand the overall process of the sequencing analysis. Then, existing work is systematically classified in accordance with generation, compression and application, and the involved SAM tools are specifically mined. Lastly, a summary and some thoughts on future directions are provided.},
	number = {5},
	urldate = {2024-05-17},
	journal = {Briefings in Bioinformatics},
	author = {Liu, Yuansheng and Shen, Xiangzhen and Gong, Yongshun and Liu, Yiping and Song, Bosheng and Zeng, Xiangxiang},
	month = sep,
	year = {2023},
	keywords = {intro},
	pages = {bbad320},
}

@misc{noauthor_fix_nodate,
	title = {Fix {Performance} {Bottlenecks} with {Intel}® {VTune}™ {Profiler}},
	url = {https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html},
	abstract = {Use advanced sampling and profiling methods to quickly analyze code, isolate issues, and deliver performance insight on modern CPUs, GPUs, and FPGAs.},
	language = {en},
	urldate = {2024-05-13},
	journal = {Intel},
}

@misc{noauthor_linuxfspipec_nodate,
	title = {linux/fs/pipe.c at master · torvalds/linux},
	url = {https://github.com/torvalds/linux/blob/master/fs/pipe.c},
	abstract = {Linux kernel source tree. Contribute to torvalds/linux development by creating an account on GitHub.},
	language = {en},
	urldate = {2024-05-06},
	journal = {GitHub},
}

@misc{tarreau_wtarreaulibslz_2024,
	title = {wtarreau/libslz},
	url = {https://github.com/wtarreau/libslz},
	abstract = {Stateless, zlib-compatible, and very fast compression library -- http://libslz.org},
	urldate = {2024-05-03},
	author = {Tarreau, Willy},
	month = may,
	year = {2024},
	note = {original-date: 2020-02-16T17:36:32Z},
}

@misc{noauthor_stateless_nodate,
	title = {Stateless {ZIP} library (libslz)},
	url = {http://www.libslz.org/},
	urldate = {2024-05-03},
}

@misc{noauthor_richgel999miniz_nodate,
	title = {richgel999/miniz: miniz: {Single} {C} source file zlib-replacement library, originally from code.google.com/p/miniz},
	url = {https://github.com/richgel999/miniz/tree/master},
	urldate = {2024-05-03},
}

@misc{noauthor_intelisa-l_2024,
	title = {intel/isa-l},
	url = {https://github.com/intel/isa-l},
	abstract = {Intelligent Storage Acceleration Library},
	urldate = {2024-05-03},
	publisher = {Intel Corporation},
	month = apr,
	year = {2024},
	note = {original-date: 2016-01-25T23:10:55Z},
}

@inproceedings{tucker_isa-l_2017,
	address = {Snowbird, UT, USA},
	title = {{ISA}-{L} {Igzip}: {Improvements} to a {Fast} {Deflate}},
	isbn = {978-1-5090-6721-3},
	shorttitle = {{ISA}-{L} {Igzip}},
	url = {http://ieeexplore.ieee.org/document/7923748/},
	doi = {10.1109/DCC.2017.88},
	urldate = {2024-05-03},
	booktitle = {2017 {Data} {Compression} {Conference} ({DCC})},
	publisher = {IEEE},
	author = {Tucker, Gregory and Oursler, Roy and Stern, Johnathan},
	month = apr,
	year = {2017},
	pages = {465--465},
}

@misc{noauthor_googlezopfli_2024,
	title = {google/zopfli},
	copyright = {Apache-2.0},
	url = {https://github.com/google/zopfli},
	abstract = {Zopfli Compression Algorithm is a compression library programmed in C to perform very good, but slow, deflate or zlib compression.},
	urldate = {2024-05-03},
	publisher = {Google},
	month = may,
	year = {2024},
	note = {original-date: 2015-03-09T10:32:36Z},
}

@misc{noauthor_cloudflarezlib_2024,
	title = {cloudflare/zlib},
	url = {https://github.com/cloudflare/zlib},
	abstract = {Cloudflare fork of zlib with massive performance improvements},
	urldate = {2024-05-03},
	publisher = {Cloudflare},
	month = may,
	year = {2024},
	note = {original-date: 2014-03-05T22:14:29Z},
}

@misc{noauthor_intelzlib_2024,
	title = {intel/zlib},
	url = {https://github.com/intel/zlib},
	urldate = {2024-05-03},
	publisher = {Intel Corporation},
	month = mar,
	year = {2024},
	note = {original-date: 2013-12-13T19:36:32Z},
}

@misc{noauthor_zlib-ngzlib-ng_2024,
	title = {zlib-ng/zlib-ng},
	copyright = {Zlib},
	url = {https://github.com/zlib-ng/zlib-ng},
	abstract = {zlib replacement with optimizations for "next generation" systems.},
	urldate = {2024-05-03},
	publisher = {zlib-ng},
	month = may,
	year = {2024},
	note = {original-date: 2014-10-13T15:47:27Z},
	keywords = {c, compression, deflate, inflate, library, optimized, zlib, zlib-license, zlib-ng, zlib-replacement},
}

@misc{noauthor_intelisa-l_nodate,
	title = {intel/isa-l: {Intelligent} {Storage} {Acceleration} {Library}},
	url = {https://github.com/intel/isa-l/tree/master},
	urldate = {2024-05-03},
}

@article{yamada_7bgzf_2020,
	title = {7bgzf: {Replacing} samtools bgzip deflation for archiving and real-time compression},
	volume = {85},
	issn = {1476-9271},
	shorttitle = {7bgzf},
	url = {https://www.sciencedirect.com/science/article/pii/S1476927119311375},
	doi = {10.1016/j.compbiolchem.2020.107207},
	abstract = {Background
Genomic sequence data are not only massive but also increasing rapidly every day; therefore, it is essential to compress such data for sharing. Though there are some specific compressors, they lack interoperability. In this study, a SAMtools bgzip variant named 7bgzf has been developed, incorporating several compression and deflation algorithms other than the widely used zlib algorithm. An extensive benchmarking study has been carried out with available data compression software.
Results
On both x64 and ARM machines, igzip performed very rapidly. For high compression, using libdeflate on the x64 platform achieved high compression with tolerable speed loss.
Conclusions
Based on appropriate algorithm selection, the proposed compression method performed better than the original bgzip method while maintaining interoperability with existing software. Therefore, this software is useful for both distribution of genomic sequence archives and real-time compression in mobile computing.},
	urldate = {2024-05-03},
	journal = {Computational Biology and Chemistry},
	author = {Yamada, Taiju},
	month = apr,
	year = {2020},
	keywords = {Deflation, Next generation sequencer, Samtools},
	pages = {107207},
}

@misc{noauthor_zlib-ngzlib-ng_2024-1,
	title = {zlib-ng/zlib-ng},
	copyright = {Zlib},
	url = {https://github.com/zlib-ng/zlib-ng},
	abstract = {zlib replacement with optimizations for "next generation" systems.},
	urldate = {2024-05-02},
	publisher = {zlib-ng},
	month = may,
	year = {2024},
	note = {original-date: 2014-10-13T15:47:27Z},
	keywords = {c, compression, deflate, inflate, library, optimized, zlib, zlib-license, zlib-ng, zlib-replacement},
}

@article{myers_intercepting_nodate,
	title = {Intercepting {Arbitrary} {Functions} on {Windows}, {UNIX}, and {Macintosh} {OS} {X} {Platforms}},
	abstract = {It is often desirable to modify the behavior of existing code bases by wrapping or replacing functions. When editing the source code of those functions is a viable option, this can be a straight-forward process. When the source of the functions cannot be edited (e.g., if the functions are provided by the system C library), then alternative techniques are required. Here, we present such techniques for UNIX, Windows, and Macintosh OS X platforms. We have used these techniques to update bioinformatics applications to call the application program interface (API) provided by the Berkeley Open Infrastructure for Network Computing (BOINC), a distributed computing toolkit.},
	language = {en},
	author = {Myers, Daniel S and Bazinet, Adam L},
}

@article{myers_intercepting_nodate-1,
	title = {Intercepting {Arbitrary} {Functions} on {Windows}, {UNIX}, and {Macintosh} {OS} {X} {Platforms}},
	abstract = {It is often desirable to modify the behavior of existing code bases by wrapping or replacing functions. When editing the source code of those functions is a viable option, this can be a straight-forward process. When the source of the functions cannot be edited (e.g., if the functions are provided by the system C library), then alternative techniques are required. Here, we present such techniques for UNIX, Windows, and Macintosh OS X platforms. We have used these techniques to update bioinformatics applications to call the application program interface (API) provided by the Berkeley Open Infrastructure for Network Computing (BOINC), a distributed computing toolkit.},
	language = {en},
	author = {Myers, Daniel S and Bazinet, Adam L},
}

@misc{noauthor_getrlimit2_nodate,
	title = {getrlimit(2) - {Linux} manual page},
	url = {https://man7.org/linux/man-pages/man2/getrlimit.2.html},
	urldate = {2024-04-26},
}

@misc{biggers_ebiggerslibdeflate_2024,
	title = {ebiggers/libdeflate},
	copyright = {MIT},
	url = {https://github.com/ebiggers/libdeflate},
	abstract = {Heavily optimized library for DEFLATE/zlib/gzip compression and decompression},
	urldate = {2024-04-22},
	author = {Biggers, Eric},
	month = apr,
	year = {2024},
	note = {original-date: 2014-12-28T05:10:42Z},
}

@article{danecek_twelve_2021,
	title = {Twelve years of {SAMtools} and {BCFtools}},
	volume = {10},
	issn = {2047-217X},
	url = {https://doi.org/10.1093/gigascience/giab008},
	doi = {10.1093/gigascience/giab008},
	abstract = {SAMtools and BCFtools are widely used programs for processing and analysing high-throughput sequencing data. They include tools for file format conversion and manipulation, sorting, querying, statistics, variant calling, and effect analysis amongst other methods.The first version appeared online 12 years ago and has been maintained and further developed ever since, with many new features and improvements added over the years. The SAMtools and BCFtools packages represent a unique collection of tools that have been used in numerous other software projects and countless genomic pipelines.Both SAMtools and BCFtools are freely available on GitHub under the permissive MIT licence, free for both non-commercial and commercial use. Both packages have been installed \&gt;1 million times via Bioconda. The source code and documentation are available from https://www.htslib.org.},
	number = {2},
	urldate = {2024-04-17},
	journal = {GigaScience},
	author = {Danecek, Petr and Bonfield, James K and Liddle, Jennifer and Marshall, John and Ohan, Valeriu and Pollard, Martin O and Whitwham, Andrew and Keane, Thomas and McCarthy, Shane A and Davies, Robert M and Li, Heng},
	month = feb,
	year = {2021},
	pages = {giab008},
}

@article{bonfield_htslib_2021,
	title = {{HTSlib}: {C} library for reading/writing high-throughput sequencing data},
	volume = {10},
	issn = {2047-217X},
	shorttitle = {{HTSlib}},
	url = {https://doi.org/10.1093/gigascience/giab007},
	doi = {10.1093/gigascience/giab007},
	abstract = {Since the original publication of the VCF and SAM formats, an explosion of software tools have been created to process these data files. To facilitate this a library was produced out of the original SAMtools implementation, with a focus on performance and robustness. The file formats themselves have become international standards under the jurisdiction of the Global Alliance for Genomics and Health.We present a software library for providing programmatic access to sequencing alignment and variant formats. It was born out of the widely used SAMtools and BCFtools applications. Considerable improvements have been made to the original code plus many new features including newer access protocols, the addition of the CRAM file format, better indexing and iterators, and better use of threading.Since the original Samtools release, performance has been considerably improved, with a BAM read-write loop running 5 times faster and BAM to SAM conversion 13 times faster (both using 16 threads, compared to Samtools 0.1.19). Widespread adoption has seen HTSlib downloaded \&gt;1 million times from GitHub and conda. The C library has been used directly by an estimated 900 GitHub projects and has been incorporated into Perl, Python, Rust, and R, significantly expanding the number of uses via other languages. HTSlib is open source and is freely available from htslib.org under MIT/BSD license.},
	number = {2},
	urldate = {2024-04-10},
	journal = {GigaScience},
	author = {Bonfield, James K and Marshall, John and Danecek, Petr and Li, Heng and Ohan, Valeriu and Whitwham, Andrew and Keane, Thomas and Davies, Robert M},
	month = feb,
	year = {2021},
	pages = {giab007},
}
