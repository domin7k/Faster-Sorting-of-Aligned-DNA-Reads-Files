\section{Input/Output} 

\subsection{Overview}
While the internal algorithms of \sort are highly optimized for parallel processing, the runtime of \sort can also be constrained by limitations of the input and output devices. 
In contrast to a program's behavior or used libraries, often the IO devices can hardly be changed. However, in certain scenarios, optimization strategies can still be employed to improve processing speed.

\subsection{Compression}\label{ioComp}
\sort outputs sorted BAM files containing aligned DNA-Reads in a BGZF compressed format. The BGZF compression format employed by \sort internally relies on GZIP compression provided by the compression library zlib. Zlib offers various compression levels (0-9), with compression level 0 resulting in uncompressed data.
The user can archive lower runtimes of \sort by using a faster implementation for GZIP compatible compression, or a lower compression level (\Cref{compression}). If the user sets the compression level to 0, \sort bypasses the compression step and outputs uncompressed data, leading to a higher throughput of \sort. 

However, taking IO requirements into account, outputting compressed files turns out to be faster than writing them uncompressed if the disk does not match the compression throughput (\Cref{fig:execIO}). 
\begin{figure}[h]
        \import{figures/}{execIOBottleneck.pgf}
    \caption{Execution time of \sort with output written to disk and to \texttt{/dev/null}. \threads \points \\ 
    Writing uncompressed data is faster than writing compressed data for up to two threads. While writing to \texttt{/dev/null} is faster on all settings, the difference between the writing targets is higher for uncompressed output.}
    \label{fig:execIO}
\end{figure}
As HTSlib compresses blockwise with every block compressed individually, compression scales well with increasing the amount of threads. Therefore, IO bottlenecks occur with higher probability when using a higher amount of threads. 

On our test system, removing the output compression leads to a speedup of approximately 3.5 on a single thread. However, on 16 threads, running \sort with the default compression level 6 takes only 62\,\% (speedup of 0.62) of the time it takes with uncompressed output (see Figure \ref{fig:execIO}).

% The reason for this is the limited write speed of the disk, which is at 56.5\,MB/s for our test setup. With uncompressed output setting,  This results in a throughput of 211.7\,MB/s in the writing phase of \sort. Due to the disk's inability to maintain the pace, the CPUs have to pause and await the completion of IO operations. 
To investigate further, we measure the IOWait time incurred during \sort's execution. The IOWait time is the time a CPU waits in IDLE for the completion of IO operations, such as writing to disk (Waiting for memory access is not counted as IOWait)~\cite{noauthor_iostat1_nodate}. For both compressed outputs from the example above, the IOWait time is below 2 seconds for every tested amount of threads. Moreover, for both compression levels, 1 and 6, the IOWait time is nearly identical, despite a difference in throughput. This observation casts doubt on the assumption that the IOWait primarily arises during the output stage for compressed output. For the uncompressed output, the IOWait time is at 2 seconds for single threaded sorting and increases with the number of threads used up to 6 seconds on using 16 additional threads, as shown in Figure \ref{fig:iowait}.
\begin{figure}
        \import{figures/}{iowaitLevels.pgf}
    \caption{IOWait time of the experiment shown in Figure \ref{fig:execIO}. IOWait time is the time all processors spend in IDLE because they are waiting for IO requests. \threads \points 
    % For compression with libdeflate using compression level 1 and 6, the IOWait time is on a similar level. For uncompressed output, the IOWait time increases to up to 6 times the IOWait time at compression usage.
    }
    \label{fig:iowait}
\end{figure}

These observations suggest an IO bottleneck on \sort with uncompressed output. However, the testing system's disk write speed exceeds 2000\,MB/s. In comparison, \sort writes 2.22\,GB in 10.5\,s, which equals a throughput of 211.7\,MB/s, if writing uncompressed output to \texttt{/dev/null} (only the time from starting the merging of temporary files to the termination of \sort). Thus, the disk's write speed should be adequate even for writing uncompressed output. Therefore, Future work should focus on a more comprehensive investigation into the reasons behind the observed increase in execution time when writing to disk compared to writing to \texttt{/dev/null}.



\subsection{Unix Pipelines}

\textit{Pipelines} are a way of forwarding the output of one program to the input of another program. In Unix-like operating systems, they connect the standard output of one program with the standard input of another program. In the Linux Kernel, this is implemented by a ring buffer in memory~\cite{noauthor_linuxfspipec_nodate}. When the output of a program is piped to the input of another, the first one writes to the buffer until the buffer is full, or the write operation is finished. If the buffer is full, the operating system halts the first program and allows the second program to read the data from the buffer. In shell scripting, users typically indicate a pipe by placing a vertical bar symbol ("\texttt{|}") between commands.


% \begin{minted}{bash} 
% ls | grep .bam 
% \end{minted}
% lists all files in the current directory using \texttt{ls} and then filters them using \texttt{grep} to display only files having ".bam" in their name. 

\subsection{Pipelining in SAMtools}
SAMtools' commands are designed to work on a stream. They process data sequentially, reading input and writing output in a single pass, without revisiting previous data.
Therefore, users can combine several SAMtools commands with Unix Pipelines. For \sort, this has the following consequences: \sort can read BAM records as soon as a potential preceding command has written them. If the potential preceding command supports this, it can give uncompressed BAM data to \sort. This eliminates the necessity for decompression in \sort and for compression for the potential preceding command. The potential IO bottleneck in writing uncompressed data is prevented by pipelining, as the outputs of the piped commands are not written to the disk but stored in memory.

Using the default compression (zlib on compression level 6), the speedup on pipelining \sort into a SAMtools \texttt{view} command compared to \sort writing a file which is afterward read by SAMtools \texttt{view}, is for all tested amounts of threads below 1.2.(\Cref{fig:pipeSpeeds}).

However, with \sort outputting uncompressed data, the speedup increases to approximately 1.8 for up to 8 used threads and 1.6 for 16 used threads.
\begin{figure}[t]
        \import{figures/}{pipeSpeed.pgf}
    \caption{Execution time comparison between different methods of chaining \sort with SAMtools \texttt{view}: \textit{Not Piped} uses "\texttt{\&\&}" for chaining, both of the others use "\texttt{|}". \sort utilizes a total of 8\,GB of RAM. With this memory setting, \sort utilizes one temporary file. \threads \points The input file is a 2.3\,GB unsorted BAM file. 
    }
    \label{fig:pipeSpeeds}
\end{figure}

\subsection{Prefixes for Temporary Files}
 \sort utilizes temporary files for its external memory sort. If no prefix is specified, it writes them into the same directory as the output. If the output is to standard output, \sort places them in the current working directory. Users can set prefixes for temporary files via the "\texttt{-T}" parameter. To reduce IOWait times, we recommend choosing a directory located on a local, high-speed disk. As temporary files are deleted automatically after successful sorting, only at the time of sorting the disks capacities are used. However, it is important to remember, that temporary files are less compressed (compression level 1) than input and output files compressed with default zlib compression (compression level 6). In combination, they typically require about 20\% more disk space, than the input file, possibly exceeding the capacity of small disks.
 
 In scenarios with limited computational power but very fast and readily available storage, e.g., sorting on a laptop, the compression of the intermediate files can be omitted. At the moment, this is only possible by changing the source code of \sort (\Cref{changeSource}). While this reduces the amount of computations \sort performs, it can lead to IO bottlenecks (\Cref{ioComp}).

\subsection{Recommendation}
The effectiveness of the IO-related recommendations presented here hinges on the specific characteristics of the employed storage devices. While these guidelines hold for our testing system, they may require adjustments based on the relative balance between computational speed and the read/write performance of the used disk.  

IO operations can limit the runtime of \sort, if it outputs uncompressed files, such as uncompressed BAM files and writes them to disk.
To reduce the amount of IO operations while also elimination compression associated overhead in the output stage of \sort, we recommend using pipelines together with uncompressed output wherever possible.

To automate the process of \sort switching to uncompressed output, detecting if its output is piped to another SAMtools command would be necessary. As this is hardly possible, we do not recommend implementing such a behavior. However, a warning should be displayed, if the output file remains unspecified. This situation commonly arises when the program is used within a pipeline. In this case, the filename of the output file is set to "\texttt{-}" and the output is forwarded to standard output using HTSlib. The change in the file name can be detected, and a warning can be printed to standard error, allowing users unfamiliar with compression options to adjust their parameters and save on computation time.

If pipelining is not possible, we recommend a compression level of 1, if \sort has more than a single thread available. If \sort is run single-threaded, writing uncompressed output leads to runtime improvements.

In Addition, we recommend users to change the prefix for temporary files to a local, high-speed disk. This is especially important to remember if pipelining if used. In this case \sort writes temporary files to the user's current working directory, which can lead to unexpected IO bottlenecks if the current working directory is e.g., a network mount.

Although modifying \sort to use uncompressed temporary files might yield performance benefits in specific scenarios, this approach is not generally applicable to most use cases. It should only be considered if computational resources are limited, while high-speed disk space is readily available.
