\section{Compression} 
Compression is a part of writing BAM files, as per default compression is applied to all BAM files and even part of the specification. Although compression of BAM files is beneficial in the long term in order to reduce storing costs and transfer speed, it comes with a significant resource overhead. 

\subsection{Analysis}
Running on 16 cores, with a total of 32GiB of memory, \sort takes 71 minutes and 57 seconds to sort a 215GB BAM file. However, \sort only uses 2 minutes and 35 seconds, which are 3.6\% of the total time, for sorting (merging not included). What is the rest of the time spend on? \\ 
Performing SAMtools \texttt{sort} on a laptop, trough various settings compression and decompression together account for around 95\% of the CPU time. Approximately 80\% are solely required by the \textit{deflate} method that is used for the compression. \\
SAMtools has outsourced all file operations to HTSlib. HTSlib depends on zlib for compression and decompression. Compression is done in blocks using the DEFLATE algorithm. Thus, compression can and is parallelized: Every time a block is to be compressed, HTSlib gives it to a thread pool of workers that compress blocks in parallel.

\subsection{Alternative zlib Implementations}
Being build into the Linux kernel, zlib is seen as the de facto standard of file compressing using the DEFLATE algorithm. The first version of zlib was published in 1995 to be used in the PNG handling library \textit{libpng}. Although still maintained, other libraries have been created that surpass zlib in both compression speed and ratio.\\
For Example, \textit{libdeflate}\cite{biggers_ebiggerslibdeflate_2024} offers fester compression while at the same time archiving a better compression ratio. Libdeflate archives this through various improvements such as using word access instead of byte access in input reading and match copying, which is a part of the DEFLATE algorithm. Furthermore, it uses a speed-up Huffman decoding process, loads the whole block into a buffer before compressing and utilizes BMI2 instructions on x86\_64 machines if supported. \\
As the developers of SAMtools are aware of the advantages of libdeflate against zlib, support for libdeflate is already built into SAMtools. Moreover, the usage is recommended and if libdeflate libraries are found, they are automatically used instead of zlib. To decide manually between using zlib and libdeflate, the HTSlib \texttt{configure} script can be run with the \texttt{--with-libdeflate} resp. \texttt{--without-libdeflate} option. \\
In addition, the user can choose to use other zlib implementations by using \texttt{LD\_PRELOAD} \cite{myers_intercepting_nodate-1}. \texttt{LD\_PRELOAD} is an environment variable telling the loader to load shared libraries. A shared library is a code object which is not part of another program but can be used by multiple programs. Functions and symbols from the shared library are connected to another program by the linker. If two different definitions for symbols exist, the linker prefers the one from a shared library in \texttt{LD\_PRELOAD}. For example, per default, HTSlib uses the \texttt{deflate} method of \texttt{libz.so}. However, the user can compile e.g. \textit{zlib-ng} \cite{noauthor_zlib-ngzlib-ng_2024}, which is API compatible to zlib, to a shared object. Then he can specify the path to the compiled shared object in \texttt{LD\_PRELOAD}. As a result, the deflate implementations of zlib-ng are used instead of the implementations of zlib. However, this approach is only possible, if the replacement implementation supports the zlib API. Therefore, other libraries, which also produce gzip compatible output but benefit from an adjusted API, can not be used for this approach. 

\subsection{7BGZF}
\textit{7BGZF} \cite{yamada_7bgzf_2020} is a tool developed by Taiju Yamada for testing different GZIP compatible compression libraries. It works by overwriting \texttt{bgzf\_compress}, the method HTSlib uses for compressing. Then it chooses the library to use for compression based on the \texttt{BGZF\_METHOD} environment variable, which the user can set before. This approach has the advantage, that it simplifies testing different compression libraries. 
To test 9 libraries, the user only has to do one installation, as 7BGZF's only dependency is \texttt{libc}. On the other hand, using 7BGZF has some disadvantages. As the method 7BGZF overwrites is a method of HTSlib, SAMtools has to link to a shared library rather to linking to the static library. However, to archive this, the user only has to change a single line in SAMtools' Makefile and change \texttt{@Hsource@HTSLIB = \$(HTSDIR)/libhts.a} to refer to \texttt{libhts.so}. Another disadvantage is, that 7BGZF does not distinguish between different compression settings, which are a parameter of the overwritten \texttt{bgzf\_compress} method. 
\begin{figure}
        \import{figures/}{compRatiosBGZF.pgf}
    \caption{Comparison of the compression ratio of different zlib implementations. Sizes are relative to the uncompressed file.}
    \label{fig:bgzfComps}
\end{figure}
Instead, 7BGZF receives the compression level to be used as part of the \texttt{BGZF\_METHOD} environment variable. Therefore, it applies the same compression level on every written BGZF compressed file. In the context of \sort, this means temporary files have the same compression level as output files. This leads to more time consumption if the output file should use a compression level which is not level 1, possibly changing the results of benchmarks. \\
Testing 7BGZF on sorting a BAM file small enough not to produce any temporary files, still gives hints on which libraries to use for faster sorting. Results of such an experiment are shown in Figure \ref{fig:bgzfComps} and \ref{fig:bgzfspeed}.
\begin{figure}[ht]
        \import{figures/}{bgzfspeed.pgf}
    \caption{Execution time of \sort using 7BGZF to test different compression libraries. Libraries are sorted after their execution time on a single thread. The compression level is the number abter the library. The inset figure also shows the performance of zopfli on level 1 and 6.}
    \label{fig:bgzfspeed}
\end{figure}


\subsubsection{Compression Levels} are  the gzip way of trading computation time against space requirements. They can be set using the "\texttt{-l}" parameter in SAMtools sort. Incidentally, this is also possible for other SAMtools commands via adding \texttt{--output-fmt-option level=1} to the arguments of the command. (Put the desired compression level between 0 and 9 instead of \texttt{1}). \\
Here it comes down to what the purpose of the sorted data is when deciding the level to be used. If the file should be archived, setting the level to 9 for maximal compression is an option. However, most of the time, sorting is a step in a larger pipeline, and the data is read and processed further soon. \\
To speed this up, it is recommended to use compression level 0 ("\texttt{-l 0}" which is equal to "\texttt{-u}") if the data is not written directly to  disc or transferred over network with limited throughput. \\
In the other case, it is recommended to use compression level 1 ("\texttt{-l 1}").

\subsection{Recomendation}
he most obvious way to increase compression speed is to increase the number of available threads. This can be done using the "\texttt{-@}" parameter. Threads are also used for parallel sorting of in memory blocks of read BAM records. This further speeds up the process.

