\section{Compression} 
Compression is a part of writing BAM files, as per default compression is applied to all BAM files and even part of the specification. Although compression of BAM files is beneficial in the long term in order to reduce storing costs and transfer speed, it comes with a significant resource overhead. \\
Performing SAMtools \texttt{sort} on a laptop, trough various settings compression and decompression together account for around 95\% of the CPU time. Approximately 80\% are solely required by the \textit{deflate} method that is responsible for the compression.

\subsection{Compression}
HTSlib depends on zlib for compression and decompression. Compression is done in blocks using the DEFLATE algorithm. Thus, compression can and is parallelized: Every time a block is to be compressed, it is given to a thread pool of workers that compress the blocks in parallel. Therefore, the most obvious way to increase compression speed is to increase the number of available threads. This can be done using the "\texttt{-@}" parameter. Threads are also used for parallel sorting of in memory blocks of read BAM records. This further speeds up the process. \\
At the same time, the single core throughput of the compression can be improved in several ways. \\

\subsubsection{Compression Levels} are  the gzip way of trading computation time against space requirements. They can be set using the "\texttt{-l}" parameter in SAMtools sort. Incidentally, this is also possible for other SAMtools commands via adding \texttt{--output-fmt-option level=1} to the arguments of the command. (Put the desired compression level between 0 and 9 instead of \texttt{1}). \\
Here it comes down to what the purpose of the sorted data is when deciding the level to be used. If the file should be archived, setting the level to 9 for maximal compression is an option. However, most of the time, sorting is a step in a larger pipeline, and the data is read and processed further soon. \\
To speed this up, it is recommended to use compression level 0 ("\texttt{-l 0}" which is equal to "\texttt{-u}") if the data is not written directly to  disc or transferred over network with limited throughput. \\
In the other case, it is recommended to use compression level 1 ("\texttt{-l 1}").

\subsubsection{Replacing zlib} by another gzip compatible DEFLATE implementations offers further savings. Being build into the Linux kernel, zlib is seen as the de facto standard of file compressing using the DEFLATE algorithm. The first version of zlib was published in 1995 to be used in the PNG handling library \textit{libpng}. Although still maintained, other libraries have been created that surpass zlib in both compression speed and ratio.\\
Especially, \textit{libdeflate}\cite{biggers_ebiggerslibdeflate_2024} offers fester compression while at the same time archiving a better compression ratio. This is archived through various improvements such as using word access instead of byte access in input reading and match copying, which is a part of the DEFLATE algorithm. Furthermore, the Huffman decoding process is speed up, the whole block is loaded into a buffer before compressing and BMI2 instructions can be used on x86\_64 machines if supported. \\
As the developers of SAMtools are aware of the advantages of libdeflate against zlib, support for libdeflate is already built into SAMtools. Moreover, the usage is recommended and if libdeflate libraries are found, they are automatically used instead of zlib. To decide manually between using zlib and libdeflate, the HTSlib \texttt{configure} script can be run with the \texttt{--with-libdeflate} resp. \texttt{--without-libdeflate} option. \\
In addition, other zlib implementations can be used by using \texttt{LD\_PRELOAD}. For this approach, they must support the zlib API. Then the new implementations override the zlib symbols and are used instead. 
