\section{Introduction}
Analysis of aligned DNA-Read data is a crucial part of modern bioinformatics with applications for scientific and medical purposes. DNA-Reads are small sequences of DNA sequences coming off a DNA sequencing machine. They are then aligned to a reference sequence to find variants, disease causing mutations and understand evolutionary relationships between species. In order to enable analyzing specific parts of a genome, such as a chromosome and to locate mutations or variations, DNA-Reads are sorted. This also improves the performance of many other downstream analysis tasks, such as finding and removing duplicate reads. \\

To address the vast amounts of data generated by modern DNA sequencing machines, highly efficient tools and data formats are needed. Developed during the 1000 Genome Project~\cite{the_1000_genomes_project_consortium_1000_2012}, the SAM and BAM format for storing alignment information to DNA sequences together with SAMtools, a tool for manipulating SAM and BAM files, have found widespread use. Along with a collection of many different commands for filtering of DNA-Reads, merging of aligned DNA-Read files and many more, SAMtools offers with \sort a tool to alternate the order of the DNA sequences stored in DNA-Read files such as SAM and BAM files. This thesis is about speeding up \sort at sorting DNA-Reads in BAM files with the goal of reducing computation costs and time. BAM is a file format capable of alignment information to DNA sequences in a binary and compressed way. Since DNA data typically occupies substantial storage space, compression is build into the BAM file format in order to reduce storage space and costs, as well as to enable faster transfer over the network.\\

\sort can arrange DNA-Read files in various orders, with sorting after the reference sequence a DNA-Read is mapped to followed by the position of the mapping on this reference sequence being the default order. This enables fast random access to specific regions of interest via index files. Index files are used in BAM files to facilitate random access despite compression. Therefore, BAM files are compressed with a special compression method allowing to access the content of the file in blocks without the necessity of decompressing all preceding blocks of the file. The compression format internally uses the compression library zlib for GZIP for compression, which is one of the most popular compression methods. With zlib being open source and used extensively in various applications such as web servers and communication, other libraries have been implemented, offering zlib compatible compression with higher throughput and higher compression efficiency. \\

In this thesis, I present three approaches to speed up the sorting of DNA-Reads stored in BAM files utilizing \sort. \sort performs an external memory sort. If not enough memory is available to \sort, it writes temporary files. If it writes a larger amount of them, it merges them, which is computational intensive. In this thesis, I analyze the impacts of \sort writing and merging temporary files. I propose parameter settings and changes in \sort's internal limitation setting, reducing the amount of merges and thus lowering the computation time of \sort. \\

\sort dedicates a significant amount of its runtime to compressing temporary and output files. To maintain the advantages of compression but reduce its impact on \sort's total runtime, I examine various zlib-compatible compression libraries and the effects of different compression levels. \\

At last, I assess the impacts of IO operations and limitations of IO devices and propose recommendations to minimize or eliminate them.



\subsection{SAMtools}
SAMtools \cite{12ySamtools} is a collection of tools to work on alignment data. It relies on the co-developed HTSlib \cite{bonfield_htslib_2021} for reading and writing information files, e.g. BAM files. SAMtools offers functionality for different operations on alignment data, such as format conversion, statistics, variant calling and many more, including the sorting, which is the focus here.

\subsection{SAM and BAM files}
A Sequence Alignment/Map (SAM) as specified by Li et al. \cite{samformat} is used to store the alignment of sequences against reference sequences. It consists of a Header Section and an Alignment Section. The Header Section contains meta information such as the format version or the sorting of the content and a dictionary of the reference sequences, whereas the Alignment Section contains aligned segments with alignment information and meta information such as the read quality. Here, a segment is a continuous sequence or subsequence of a raw DNA read. \\
The alignment information mainly consists of the ID of the reference sequence the alignment is mapped to, the position where the alignment starts in the reference sequence and a CIGAR string providing the alignment at this position. The CIGAR String as specified in \cite{samformat} lists i.a. sequential matches, mismatches, insertions and deletions and therefore represents the alignment of the corresponding segment and its reference sequence. \\
A BAM file is the binary representation of a SAM file. The main differences are the usage of a 4-bit encoding for the sequences, 3-bit for CIGAR Symbols and a 0-based instead of 1-based coordinate system for the position. \\
Furthermore, a BAM file is per default \textit{BGZF} compressed.

\subsection{BGZF Compression}
BGZF is a lossless compression method proposed at the same time as the BAM format. Widely used compression methods like GZIP compress a file from the beginning to the end in one piece. This has the advantage that matching pieces of the file can be found over a larger span. However, to decrypt such a compressed file, it also needs to be read from the beginning and, depending on the compression method, decompressed at least until the point of interest. Since alignment data can produce very large files but not all of their regions are needed for every use case, it is beneficial to enable some form of random access. To archive this, BGZF utilizes \textit{GZIP} \cite{gzip} and the \textit{DEFLATE} algorithm \cite{deflate} by Phil Katz to compress large files into blocks of less than 64KB size (compressed and uncompressed). These blocks are the concatenated. Thus, fast random access using index files is possible. In an index file, the position of a piece of information is stored in a 64-bit integer. It consists of a 48-bit unsigned integer \textit{coffset} indicating the number of the compressed block and a 16-bit unsigned integer \textit{uoffset} describing the position in the uncompressed block. \\
Besides this, the BGZF format also provides compatibility with GZIP. As GZIP allows this combination of multiple compressed files to one file, a BGZF-compressed file can be decompressed by any standard GZIP implementation. This can be practical if for example a SAM file that can be viewed with any text editor is compressed using BGZF. \\
Like GZIP, BGZF supports compression levels ranging from 1 (fastest but worst) to 9 (slowest but best) which are basically the compression levels used for the underlying GZIP compression. The compression levels affect the size of the compressed files as shown in Figure \ref{fig:compSizes}.
\begin{figure}
        \import{figures/}{compSizes.pgf}
    \caption{Comparison of the size of BGZF compressed files on all compression levels, exemplified using a 10.4GiB unsorted BAM file.}
    \label{fig:compSizes}
\end{figure}
The speed of the compression depends mainly on the compression level, the GZIP-implementation and the number of used threads (see Figure \ref{fig:compSpeed}).  
\begin{figure}
        \import{figures/}{compSpeed.pgf}
    \caption{Comparison of the output rate of HTSlib's \texttt{bgzip} which uses BGZF to compress A 10.4GiB unsorted BAM file. For reference, compression level 0 is plotted in the smaller inset plot.}
    \label{fig:compSpeed}
\end{figure}
To measure the compression speed while minimizing the influence of the sort and merge processes, the speed of HTSlib's \texttt{bgzip} can be measured. This is a tool using BGZF to compress arbitrary files. As its inner mechanisms are exactly the same as the compression part of SAMtools' \texttt{sort} tool (use the same underlying HTSlib methods), pipelining \texttt{bgzip}'s output to \texttt{/dev/null} gives an estimation of the computation time needed only for compression at using SAMtools \texttt{sort}. This still holds for compression level 0. At this level, the input is not compressed, but directly written to the output.

