\section{Introduction}
Analysis of aligned DNA-Read data is a crucial part of modern bioinformatics with applications for scientific and medical purposes. DNA-Reads are small sequences of DNA sequences coming off a DNA sequencing machine. They are then aligned to a reference sequence to find variants, disease causing mutations and understand evolutionary relationships between species. In order to analyze specific parts of a genome, such as a chromosome and to locate mutations or variations, DNA-Reads are sorted. This also improves the performance of many other downstream analysis tasks, for example finding and removing duplicate reads. \\

To address the vast amounts of data generated by modern DNA sequencing machines, highly efficient tools and data formats are needed. Developed during the 1000 Genome Project~\cite{the_1000_genomes_project_consortium_1000_2012}, the SAM and BAM formats for storing alignment information to DNA sequences, have found widespread use. Developed alongside these formats, SAMtools became a standard tool for manipulating SAM and BAM files. Next to a collection of many different commands for filtering DNA-Reads, merging of aligned DNA-Read files and many more, SAMtools offers with \sort a tool to alternate the order of the DNA sequences stored in DNA-Read files such as SAM and BAM files. \\

This thesis is about speeding up \sort at sorting DNA-Reads in BAM files with the goal of reducing computation costs and time. BAM is a file format capable of alignment information to DNA sequences in a binary and compressed way. Since DNA data typically occupies substantial storage space, compression is build into the BAM file format in order to reduce storage space and costs, as well as to enable faster transfer over the network.\\

\sort can arrange DNA-Read files in various orders. The default order involves sorting by the reference sequence to which a DNA read is mapped, followed by the position of the mapping on this reference sequence. This enables fast random access to specific regions of interest via index files. \\

Index files are used in the handling of BAM files to facilitate random access despite compression. BAM files are compressed with a special compression method allowing to access the content of the file in blocks without the necessity of decompressing all preceding blocks of the file. The compression format internally uses the compression library zlib for GZIP for compression, which is one of the most popular compression methods. With zlib being open source and used extensively in various applications such as web servers and communication, other libraries have been implemented, offering zlib compatible compression with higher throughput and higher compression efficiency. \\

In this thesis, I present three approaches to speed up the sorting of DNA-Reads stored in BAM files utilizing \sort. \\

\sort performs an external memory sort. If not enough memory is available to \sort, it writes temporary files. If it writes a larger amount of them, it merges them, which is computational intensive. In this thesis, I analyze the impacts of \sort writing and merging temporary files. I propose parameter settings and changes in \sort's internal limitation setting, reducing the amount of merges and thus lowering the computation time of \sort. \\

\sort dedicates a significant amount of its runtime to compressing temporary and output files. To maintain the advantages of compression but reduce its impact on \sort's total runtime, I examine various zlib-compatible compression libraries and the effects of different compression levels. \\

At last, I assess the impacts of IO operations and limitations of IO devices and propose recommendations to minimize or eliminate them.



\subsection{SAMtools}
SAMtools~\cite{12ySamtools} is a collection of tools to work on alignment data, such as aligned DNA-Reads. It relies on the co-developed HTSlib~\cite{bonfield_htslib_2021} for reading and writing information files, e.g. BAM files. SAMtools offers functionality for different operations on alignment data, such as format conversion, statistics, variant calling and many more, including the sorting, which is the focus here. \\

\subsection{Aligned DNA-Reads}
DNA-Reads are sequences of bases coming from a sequencing machine. They can consist of multiple contiguous sequences. Aligned DNA-Reads are DNA-Reads aligned to a reference sequence. The alignment may include insertions, deletions, mismatches, and skipped parts of the reference sequence. Additionally, clipping removes low-quality portions of the sequenced fragment to improve the alignment of the remaining high-quality sequence with the reference. Also, changes in directions on the reference are possible.

\subsection{SAM and BAM files}
A Sequence Alignment Map (SAM) as specified by Li et al.~\cite{samformat} is used to store the alignment of sequences against reference sequences. It consists of a header section and an alignment section. The header section contains meta information such as the format version or the sorting of the content and a dictionary of the reference sequences, whereas the alignment section contains aligned segments with alignment information and meta information such as the read quality. A segment is a continuous sequence or subsequence of a raw DNA-Read. Aligned DNA-Reads are eventually put into multiple records with different segments in the alignment section, as single BAM records can not store changes in directions of the alignment on the reference sequence.\\

The alignment information primarily includes the ID of the reference sequence to which the alignment is mapped, the position in the reference sequence where the alignment starts, and a CIGAR string detailing the alignment at this position. The CIGAR String consists of a list of symbols representing sequential matches, mismatches, insertions, and deletions. Therefore, it represents the alignment of the corresponding segment and its reference sequence. \\

A BAM file is the binary representation of a SAM file. The main differences are the usage of a 4-bit encoding for the sequences, a 3-bit encoding for CIGAR Symbols and a 0-based instead of 1-based coordinate system for the position. Furthermore, a BAM file is per default \textit{BGZF} compressed.

\subsection{BGZF Compression} \label{bgzf}
BGZF, short for Blocked GNU Zip Format, is a lossless compression method proposed at the same time as the BAM format. Widely used compression methods like GZIP compress a file from the beginning to the end in one piece. This has the advantage of allowing matching segments of the file to be located over a greater range. Thus, the compression method is able to reduce the file size more effectively, as repeated sequences can be identified throughout the entire file. However, to decompress such a compressed file, it also needs to be read from the beginning and, depending on the compression method, decompressed at least until the point of interest. \\

Since alignment data can produce very large files but not all of their regions are needed for every use case, it is beneficial to enable some form of random access. To archive this, BGZF utilizes GZIP~\cite{gzip} to compress large files into blocks of less than 64\,KB size (compressed and uncompressed). GZIP uses the DEFLATE algorithm~\cite{deflate} by Phil Katz to compress these individual blocks, which it then subsequently concatenates. Thus, fast random access using index files is possible. In an index file, the position of a piece of information is stored in a 64-bit integer. It consists of a 48-bit unsigned integer \textit{coffset} indicating the number of the compressed block and a 16-bit unsigned integer \textit{uoffset} describing the position in the uncompressed block. \\

Also, the BGZF format provides compatibility with GZIP. Any file compressed utilizing BGZF can be decompressed by any standard GZIP decompression implementation, as GZIP allows this combination of multiple compressed files to one file. Given that Gzip is highly prevalent as a compression technique, there are numerous compatible compression and decompression libraries for all platforms. Thus, employing the open-source GZIP internally simplifies the development of other legacy tools working with BGZF-compatible compression.  \\

Like GZIP, BGZF supports compression levels ranging from 1 (fastest but worst) to 9 (slowest but best) mirroring the compression levels used for the underlying GZIP compression. The compression levels affect the size of the compressed files, as shown in Figure~\ref{fig:compSizes}.
\begin{figure}[t]
        \import{figures/}{compSizes.pgf}
    \caption{Comparison of the size of BGZF compressed files on all compression levels, exemplified using a 10.4\,GiB unsorted BAM file. \\
    Although no compression yields a file four times as large, the distinctions between compression levels are less significant.}
    \label{fig:compSizes}
\end{figure}
The speed of the compression depends mainly on the compression level, the GZIP-implementation and the number of used threads (see Figure \ref{fig:compSpeed}).  
\begin{figure}
        \import{figures/}{compSpeed.pgf}
    \caption{Comparison of the output rate of HTSlib's \texttt{bgzip} which uses BGZF to compress A 10.4GiB unsorted BAM file. For reference, compression level 0 is plotted in the smaller inset plot. \\
    While no compression significantly outpaces every compression level, the throughput increments between the compression levels are consistent.}
    \label{fig:compSpeed}
\end{figure}
To measure the compression speed, I measure the speed of HTSlib's \texttt{bgzip}. This is a tool to compress arbitrary files using BGZF. \sort uses the same methods as \texttt{bgzip} of HTSlib, the library utilized by SAMtools for compression and file operations. This still holds for compression level 0. For this compression level, \texttt{bgzip} as well as \sort do not compress, but directly written the output. Therefore, the compression speed of \texttt{bgzip} is relevant for sorting because it sets a lower boundary on writing the output of \sort, considering that \sort also needs to compress its output.
