\section{Analysis (Version 1.19.2)}

\subsection{Algorithm}
\input{chapters/current_behavior}
\FloatBarrier

\subsection{Time Allocation}
Understanding the resource utilization and the time allocation of the different parts of the sorting process is crucial to be able to optimize its computation time. However, the process has different points of constraint on different machines, as we will see in the following. \\
In general, high time consumption of the SAMtools \texttt{sort} method can be traced to three main blocks.

\subsubsection{Compression} is a part of writing BAM files, as per default compression is applied to all BAM files and even part of the specification. Although compression of BAM files is beneficial in the long term in order to reduce storing costs and transfer speed, it comes with a significant resource overhead. \\
Performing SAMtools \texttt{sort} on a laptop, trough various settings compression and decompression together account for around 95\% of the CPU time. Approximately 80\% are solely required by the \textit{deflate} method that is responsible for the compression.

\subsubsection{IO} can also be a constraint of the sorting process. As the internal mechanisms of SAMtools usually work very fast and are highly parallel, but have to process huge amounts of data, input and output devices can also limit the computation speed.

\subsubsection{Temporary Files} are necessary for SAMtools sort to work as a stream while processing more data than can be held in memory. Unfortunately, writing temporary files is time-consuming. Thus, the amount of temporary files should be minimized. More specific, a BAM record should be written as infrequently as possible. On the other hand, limitations of the Operating System have to be taken into consideration.

\subsection{Compression}
HTSlib is the tool used by SAMtools to perform all file operations. On its README, it claims its only dependency to be \textit{zlib}. zlib is a library used for compression utilizing the DEFLATE algorithm. 

\subsection{IO}


\subsection{Temporary Files}
SAMtools \texttt{sort} has, as mentioned above, a hard coded limit for temporary files. Moreover, this limit is reached very late because of multi level merging. \\
To understand how many temporary files are written, we have to look into the algorithm for merging. The first variable influencing the generation of temporary files is the memory limit. Defaulting to 768MiB, it gets multiplied by the number of threads. The result is the limit up to which BAM records are read in one block. This is also a good approximation for the size of a small temporary file before compression. At least one MiB per thread is enforced to prevent the creation of a huge amount of temporary files. Intuitively, one would think, that the sorting gets faster the more memory can be used. Figure \ref{fig:maxMems}
\begin{figure}
        \import{figures/}{maxMems.pgf}
    \caption{Execution time of SAMtools \texttt{sort} on a 2.4GB BAM file using default parameters except \texttt{-m} for memory limitation setting. }
    \label{fig:maxMems}
\end{figure}