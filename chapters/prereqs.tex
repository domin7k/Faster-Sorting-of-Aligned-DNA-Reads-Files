\section{Prerequisites}

\subsection{SAMtools}
SAMtools~\cite{12ySamtools} is a collection of tools to work on alignment data, such as aligned DNA-Reads. It relies on the co-developed HTSlib~\cite{bonfield_htslib_2021} for reading and writing information files, namely SAM, BAM, and CRAM files. SAMtools offers functionality for different operations on alignment data, such as format conversion, statistics, variant calling and many more, including sorting, which is the focus here. 

\subsection{Aligned DNA-Reads}
DNA-Reads are short (typically 250â€“800 nucleotides long~\cite{hu_next-generation_2021}) sequences of nucleotides, the fundamental building blocks of DNA. These nucleotides are denoted by their bases, adenine (\texttt{A}), guanine (\texttt{G}), cytosine (\texttt{C}), and thymine (\texttt{T}). A DNA-Read can consist of multiple contiguous sequences. 

Aligned DNA-Reads are DNA-Reads aligned to a reference sequence. The alignment may include insertions, deletions, mismatches, and skipped parts of the reference sequence. Additionally, a step called \textit{clipping} excludes parts of the sequenced fragment with low read qualities from the alignment to improve the alignment of the remaining high-quality sequence with the reference. Also, changes in the direction of the alignment on the reference are possible. In alignment files, changes in direction of the alignment lead to splitting up the DNA-Read into multiple sequences, one for each contiguous part of the DNA-Read aligned in the same direction.

\subsection{SAM and BAM files}
A SAM (Sequence Alignment Map) file as specified by Li et al.~\cite{samformat} is used to store the alignment of sequences against reference sequences. It consists of a header section and an alignment section. The header section contains meta information such as the format version or the sorting of the content and a dictionary of the reference sequences, whereas the alignment section contains aligned segments with alignment information and meta information such as the read quality. A segment is a continuous sequence or subsequence of a raw DNA-Read. Aligned DNA-Reads are eventually put into multiple records with different segments in the alignment section, as single BAM records can not store changes in directions of the alignment on the reference sequence.

The alignment information primarily includes the ID of the reference sequence to which the alignment is mapped, the position in the reference sequence where the alignment starts, and detail on the alignment of this position (match, mismatch, insertion, or deletion). 

A BAM (Binary Alignment Map) file is the binary representation of a SAM file. Compared to the SAM format, this format utilizes a 4-bit encoding for DNA sequences, a 3-bit encoding for CIGAR symbols, and adopts a 0-based coordinate system for positions. Furthermore, a BAM file is per default \textit{BGZF} compressed.

\subsection{The DEFLATE format and algorithm}
The DEFLATE format~\cite{deflate} is a format specifying data compressed with a combination of an LZ77 algorithm~\cite{ziv_universal_1977} and Huffman Coding~\cite{huffman_method_1952}. The compressed data consists of subsequent blocks. The blocks contain strings and pointers to previous strings, which contain the distance to and the length of the matching part. The bytes of the strings which are no duplicates of previous found strings and the pointers, which consist of distances and lengths, are compressed using Huffman coding. The trees representing the Huffman codes are Huffman coded as well. 
The DEFLATE algorithm is an algorithm capable of producing an output stream in the DEFLATE format given an input data stream.

\subsection{GZIP and zlib}
GZIP~\cite{gzip} is a container format for data compressed in the DEFLATE format. A GZIP file consists of a series of \textit{members} which consist of a header, a series of compressed blocks, and a footer. The header contains meta information on the compressed files (e.g., the file name and the modification time) and can also contain extra fields which in the BGZF file format are used to identify a member as part of a BGZF file and store the length of the compressed member. The compressed blocks contain the compressed data and the footer contains a checksum and the size of the uncompressed content of the blocks modulo $2^{32}$. 

The c library zlib is an implementation of the DEFLATE algorithm. It can produce output in GZIP, ZLIB, or raw DEFLATE format. The ZLIB format is a wrapper for DEFLATE similar to the GZIP format but with less header information and another checksum algorithm (Adler32 instead of crc32).


\subsection{BGZF Compression} \label{bgzf}
The Blocked GNU Zip Format (BGZF), is a lossless compression method proposed together with the BAM format. Widely used compression methods like GZIP compress a file from the beginning to the end in one piece. This has the advantage of allowing matching segments of the file to be located over a greater range. Thus, the compression method is able to reduce the file size more effectively, as repeated sequences can be identified throughout the entire file. However, to decompress such a compressed file, it also needs to be read from the beginning and, depending on the compression method, decompressed at least until the point of interest. 

Given that not all regions of large alignment data files are relevant for every analysis, random access is required for efficient analysis of specific data subsets. To archive this, BGZF utilizes GZIP~\cite{gzip} to compress large files into blocks of less than 64\,KB size (compressed and uncompressed). GZIP uses the DEFLATE algorithm~\cite{deflate} to compress these individual blocks, which it then subsequently concatenates. Thus, fast random access using index files is possible. In an index file, the position of a piece of information is stored as a 64\,bit integer. This index is divided into a 48\,bit block index and a 16\,bit offset in the respective block.

The BGZF format leverages compatibility with GZIP, enabling any standard GZIP decompression tool to handle BGZF-compressed files. This compatibility stems from BGZF exploiting GZIP's ability to combine multiple compressed blocks into a single file. Given that Gzip is highly prevalent as a compression technique, there are numerous compatible compression and decompression libraries for all platforms. Thus, employing the open-source GZIP internally simplifies the development of other legacy tools working with BGZF-compatible compression.  

Like GZIP, BGZF supports compression levels ranging from 1 (fastest but largest file size) to 9 (slowest but smallest file size) analogously to the compression levels used for the underlying GZIP compression. The compression levels affect the size of the compressed aligned DNA-Read files, as shown in Figure~\ref{fig:compSizes}.
\begin{figure}[htb]
        \import{figures/}{compSizes.pgf}
    \caption{Comparison of the size of BGZF compressed files on all compression levels, exemplified using a 10.4\,GiB unsorted BAM file. 
    Although no compression yields a file four times as large, the distinctions between compression levels are less substantial.}
    \label{fig:compSizes}
\end{figure}
The speed of the compression depends mainly on the compression level, the GZIP-implementation and the number of used threads (see Figure \ref{fig:compSpeed}).  
\begin{figure}[htb]
        \import{figures/}{compSpeed.pgf}
    \caption{Comparison of the output rate of HTSlib's \texttt{bgzip} which uses BGZF to compress A 10.4\,GiB unsorted BAM file. For reference, compression level 0 is plotted in the smaller inset plot.}
    \label{fig:compSpeed}
\end{figure}
To measure the compression speed, we measure the speed of HTSlib's \texttt{bgzip}, a tool to compress arbitrary files using BGZF. \sort uses the same methods as \texttt{bgzip} of HTSlib, the library utilized by SAMtools for compression and file operations. This still holds for compression level 0. For this compression level, \texttt{bgzip} as well as \sort do not compress, but directly written the output. Therefore, the compression speed of \texttt{bgzip} is relevant for sorting because it sets a lower boundary on writing the output of \sort, considering that compression is a part of creating BAM files.
